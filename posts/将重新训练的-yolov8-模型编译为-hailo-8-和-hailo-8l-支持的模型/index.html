<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><style>:root{--accent-color:#FF4D4D}</style><title>将重新训练的 Yolov8 模型编译为 Hailo 8 和 Hailo 8L 支持的模型</title>
<meta name=description content="在 Ubuntu 22 将自行训练的 Yolov8n 模型编译为 Hailo8/Hailo8L 支持的 hef 格式的模型，在 Hailo8 上使用自行训练的模型进行对象检测
1. 环境准备 anaconda 参考 Installing on Linux 安装
2. 训练 yolo 模型 2.1 安装依赖 创建环境 单 …"><meta name=keywords content='blog,hugo,Ubuntu,Hailo,TPU'><meta property="og:url" content="https://blog.hellowood.dev/posts/%E5%B0%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E7%9A%84-yolov8-%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91%E4%B8%BA-hailo-8-%E5%92%8C-hailo-8l-%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B/"><meta property="og:type" content="website"><meta property="og:title" content="将重新训练的 Yolov8 模型编译为 Hailo 8 和 Hailo 8L 支持的模型"><meta property="og:description" content="在 Ubuntu 22 将自行训练的 Yolov8n 模型编译为 Hailo8/Hailo8L 支持的 hef 格式的模型，在 Hailo8 上使用自行训练的模型进行对象检测
1. 环境准备 anaconda 参考 Installing on Linux 安装
2. 训练 yolo 模型 2.1 安装依赖 创建环境 单 …"><meta property="og:image" content="https://blog.hellowood.dev/images/avatar.webp"><meta property="og:image:secure_url" content="https://blog.hellowood.dev/images/avatar.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="将重新训练的 Yolov8 模型编译为 Hailo 8 和 Hailo 8L 支持的模型"><meta name=twitter:description content="在 Ubuntu 22 将自行训练的 Yolov8n 模型编译为 Hailo8/Hailo8L 支持的 hef 格式的模型，在 Hailo8 上使用自行训练的模型进行对象检测
1. 环境准备 anaconda 参考 Installing on Linux 安装
2. 训练 yolo 模型 2.1 安装依赖 创建环境 单 …"><meta property="twitter:domain" content="https://blog.hellowood.dev/posts/%E5%B0%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E7%9A%84-yolov8-%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91%E4%B8%BA-hailo-8-%E5%92%8C-hailo-8l-%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B/"><meta property="twitter:url" content="https://blog.hellowood.dev/posts/%E5%B0%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E7%9A%84-yolov8-%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91%E4%B8%BA-hailo-8-%E5%92%8C-hailo-8l-%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B/"><meta name=twitter:image content="https://blog.hellowood.dev/images/avatar.webp"><link rel=canonical href=https://blog.hellowood.dev/posts/%E5%B0%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E7%9A%84-yolov8-%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91%E4%B8%BA-hailo-8-%E5%92%8C-hailo-8l-%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B/><link rel=stylesheet type=text/css href=/css/normalize.min.css media=print><link rel=stylesheet type=text/css href=/css/main.min.css><link id=dark-theme rel=stylesheet href=/css/dark.min.css><script src=/js/bundle.min.3eb19cb61dde9e37b9522867f3e024aeb68e26ab8e03252e46e365abcb19acf7.js integrity="sha256-PrGcth3enje5Uihn8+AkrraOJquOAyUuRuNlq8sZrPc="></script><link rel=stylesheet type=text/css href=/css/custom.css><script defer src=https://umami.hellowood.dev/script.js data-website-id=7a9034de-0ce7-4756-942a-829e6cd22301></script><script defer src=https://cloud.umami.is/script.js data-website-id=73ff1c8c-9938-43cf-81af-e77e26b0cca3></script><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "b2e481d136dc428c8c96c8673e2a04cf"}'></script><meta name=google-adsense-account content="ca-pub-3401351766168985"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3401351766168985" crossorigin=anonymous></script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","jtbhx98g62")</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-3MSGPYTHPZ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-3MSGPYTHPZ")</script></head><body><script>setThemeByUserPref()</script><header class=header><nav class=header-nav><div class=avatar><a href=https://blog.hellowood.dev/><img src=/images/avatar.webp alt=avatar></a></div><div class=nav-title><a class=nav-brand href=https://blog.hellowood.dev/>HelloWood</a></div><div class=nav-links><div class=nav-link><a href=https://blog.hellowood.dev/ aria-label><span data-feather=home></span> Home</a></div><div class=nav-link><a href=https://blog.hellowood.dev/posts/ aria-label><span data-feather=book></span> Posts</a></div><div class=nav-link><a href=https://blog.hellowood.dev/tags/ aria-label><span data-feather=tag></span> Tags</a></div><div class=nav-link><a href=https://github.com/helloworlde aria-label=github><span data-feather=github></span></a></div><div class=nav-link><a href=https://umami.hellowood.dev/share/lab/Blog aria-label=dashboard><span data-feather=pie-chart></span></a></div><div class=nav-link><a href=https://blog.hellowood.dev/index.xml aria-label=rss><span data-feather=rss></span></a></div><span class=nav-icons-divider></span><div class="nav-link dark-theme-toggle"><span class="sr-only dark-theme-toggle-screen-reader-target">theme</span>
<a aria-hidden=true role=switch><span class=theme-toggle-icon data-feather=moon></span></a></div><div class=nav-link id=hamburger-menu-toggle><span class="sr-only hamburger-menu-toggle-screen-reader-target">menu</span>
<a aria-checked=false aria-labelledby=hamburger-menu-toggle id=hamburger-menu-toggle-target role=switch><span data-feather=menu></span></a></div><ul class="nav-hamburger-list visibility-hidden"><li class=nav-item><a href=https://blog.hellowood.dev/><span data-feather=home></span> Home</a></li><li class=nav-item><a href=https://blog.hellowood.dev/posts/><span data-feather=book></span> Posts</a></li><li class=nav-item><a href=https://blog.hellowood.dev/tags/><span data-feather=tag></span> Tags</a></li><li class=nav-item><a href=https://github.com/helloworlde><span data-feather=github></span></a></li><li class=nav-item><a href=https://umami.hellowood.dev/share/lab/Blog><span data-feather=pie-chart></span></a></li><li class=nav-item><a href=https://blog.hellowood.dev/index.xml><span data-feather=rss></span></a></li><li class="nav-item dark-theme-toggle"><span class="sr-only dark-theme-toggle-screen-reader-target">theme</span>
<a role=switch><span class=theme-toggle-icon data-feather=moon></span></a></li></ul></div></nav></header><main id=content><div class="post container"><div class=post-header-section><h1>将重新训练的 Yolov8 模型编译为 Hailo 8 和 Hailo 8L 支持的模型</h1><small role=doc-subtitle></small><p class=post-date>2024-09-09</p><ul class=post-tags><li class=post-tag><a href=https://blog.hellowood.dev/tags/ubuntu>Ubuntu</a></li><li class=post-tag><a href=https://blog.hellowood.dev/tags/hailo>Hailo</a></li><li class=post-tag><a href=https://blog.hellowood.dev/tags/tpu>TPU</a></li></ul></div><div class=post-content><p>在 Ubuntu 22 将自行训练的 Yolov8n 模型编译为 Hailo8/Hailo8L 支持的 hef 格式的模型，在 Hailo8 上使用自行训练的模型进行对象检测</p><h2 id=1-环境准备>1. 环境准备</h2><ul><li>anaconda</li></ul><p>参考 <a href=https://docs.anaconda.com/anaconda/install/linux/>Installing on Linux</a> 安装</p><h2 id=2-训练-yolo-模型>2. 训练 yolo 模型</h2><h3 id=21-安装依赖>2.1 安装依赖</h3><ul><li>创建环境</li></ul><p>单独创建 ultralytics 的环境，用于训练和导出 yolo 模型为其他格式</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda create -n ultralytics <span style=color:#dcaeea>python</span><span style=color:#c7bf54>=</span>3.10
</span></span></code></pre></div><ul><li>激活环境</li></ul><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda activate ultralytics
</span></span></code></pre></div><ul><li>安装 ultralytics</li></ul><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install ultralytics
</span></span></code></pre></div><p>等待安装完成后就可以使用 <code>yolo</code> 命令训练和导出模型了</p><h3 id=22-训练模型>2.2 训练模型</h3><p>训练模型可以参考 roboflow 的博客 <a href=https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/>How to Train YOLOv8 Object Detection on a Custom Dataset</a>；为了测试验证流程，先使用官方提供的 yolov8n 当作训练的模型，可以从 <a href=https://github.com/ultralytics/assets/releases>https://github.com/ultralytics/assets/releases/</a> 下载，以 yolov8n 为例，下载地址为 <a href=https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt>https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt</a></p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt
</span></span></code></pre></div><h3 id=23-将模型导出为-onnx-格式>2.3 将模型导出为 onnx 格式</h3><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yolo <span style=color:#ef8383>export</span> <span style=color:#dcaeea>model</span><span style=color:#c7bf54>=</span>./yolov8n.pt <span style=color:#dcaeea>imgsz</span><span style=color:#c7bf54>=</span><span style=color:#d19a66>640</span> <span style=color:#dcaeea>format</span><span style=color:#c7bf54>=</span>onnx <span style=color:#dcaeea>opset</span><span style=color:#c7bf54>=</span><span style=color:#d19a66>11</span>
</span></span></code></pre></div><p>imgsz=640 指定输入图片的尺寸（图像大小），即 640x640。这个尺寸是模型在推理时处理图像的分辨率</p><p>format=onnx 指定导出的模型格式为 ONNX（Open Neural Network Exchange）。ONNX 是一种支持在不同深度学习框架间转换和共享模型的开放格式</p><p>opset=11 指定 ONNX 的操作集版本为 11</p><h2 id=3-编译为-hailo-模型>3. 编译为 Hailo 模型</h2><h3 id=31-准备环境>3.1 准备环境</h3><h4 id=311-创建环境>3.1.1 创建环境</h4><ul><li>创建环境</li></ul><p>单独创建一个 hailo 的环境，避免和 ultralytics 依赖冲突</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda create -n hailo <span style=color:#dcaeea>python</span><span style=color:#c7bf54>=</span>3.10
</span></span></code></pre></div><ul><li>激活环境</li></ul><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda activate hailo
</span></span></code></pre></div><h4 id=312-安装-hailo_model_zoo>3.1.2 安装 hailo_model_zoo</h4><ul><li>安装 hailo_model_zoo</li></ul><p>从 <a href=https://hailo.ai/developer-zone/software-downloads/>Developer Zone</a> 下载并安装 hailo_model_zoo</p><p><img src=https://img.hellowood.dev/picture/homelab-tpu-hailo-software-download-hailo-model-zoo.png alt=homelab-tpu-hailo-software-download-hailo-model-zoo.png></p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install hailo_model_zoo-2.12.0-py3-none-any.whl
</span></span></code></pre></div><h4 id=313-准备-coco-数据集>3.1.3 准备 Coco 数据集</h4><p>安装 Coco 数据集，用于评估、优化和编译模型；因为是通过 conda 安装的，代码所在路径是 conda env 路径 + 环境名称 + 包路径，即 <code>~/anaconda3/envs/hailo/lib/python3.10/site-packages/hailo_model_zoo</code></p><ul><li>准备 val 数据</li></ul><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python ~/anaconda3/envs/hailo/lib/python3.10/site-packages/hailo_model_zoo/datasets/create_coco_tfrecord.py val2017
</span></span></code></pre></div><p>将会下载 coco 的 val 数据到 <code>~/.hailomz</code> 路径下；val 数据用于验证模型</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>2024-09-08 16:53:52.437311: I tensorflow/core/util/port.cc:110<span style=color:#c7bf54>]</span> oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, <span style=color:#ef8383>set</span> the environment variable <span style=color:#98c379>`</span><span style=color:#dcaeea>TF_ENABLE_ONEDNN_OPTS</span><span style=color:#c7bf54>=</span>0<span style=color:#98c379>`</span>.
</span></span><span style=display:flex><span>2024-09-08 16:53:52.438390: I tensorflow/tsl/cuda/cudart_stub.cc:28<span style=color:#c7bf54>]</span> Could not find cuda drivers on your machine, GPU will not be used.
</span></span><span style=display:flex><span>2024-09-08 16:53:52.458864: I tensorflow/tsl/cuda/cudart_stub.cc:28<span style=color:#c7bf54>]</span> Could not find cuda drivers on your machine, GPU will not be used.
</span></span><span style=display:flex><span>2024-09-08 16:53:52.459101: I tensorflow/core/platform/cpu_feature_guard.cc:182<span style=color:#c7bf54>]</span> This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
</span></span><span style=display:flex><span>To <span style=color:#ef8383>enable</span> the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
</span></span><span style=display:flex><span>2024-09-08 16:53:52.747289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38<span style=color:#c7bf54>]</span> TF-TRT Warning: Could not find TensorRT
</span></span><span style=display:flex><span><span style=color:#d19a66>48</span> / <span style=color:#d19a66>5000</span> images have no annotations
</span></span><span style=display:flex><span>val2017 <span style=color:#8a93a5;font-style:italic>#5000: /home/ubuntu/.hailomz/data/coco/val2017/000000365098.jpg: 100%|████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:09&lt;00:00, 526.82it/s]</span>
</span></span></code></pre></div><ul><li>准备 calib 数据</li></ul><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python ~/anaconda3/envs/hailo/lib/python3.10/site-packages/hailo_model_zoo/datasets/create_coco_tfrecord.py calib2017
</span></span></code></pre></div><p>会下载名为 <code>train2017.zip</code> 大约 18G 的 Coco 数据集解压并处理，路径是 <code>～/.hailomz</code>；calib 数据集用于模型的量化校准</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>2024-09-08 16:54:19.758265: I tensorflow/core/util/port.cc:110<span style=color:#c7bf54>]</span> oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, <span style=color:#ef8383>set</span> the environment variable <span style=color:#98c379>`</span><span style=color:#dcaeea>TF_ENABLE_ONEDNN_OPTS</span><span style=color:#c7bf54>=</span>0<span style=color:#98c379>`</span>.
</span></span><span style=display:flex><span>2024-09-08 16:54:19.759360: I tensorflow/tsl/cuda/cudart_stub.cc:28<span style=color:#c7bf54>]</span> Could not find cuda drivers on your machine, GPU will not be used.
</span></span><span style=display:flex><span>2024-09-08 16:54:19.779913: I tensorflow/tsl/cuda/cudart_stub.cc:28<span style=color:#c7bf54>]</span> Could not find cuda drivers on your machine, GPU will not be used.
</span></span><span style=display:flex><span>2024-09-08 16:54:19.780151: I tensorflow/core/platform/cpu_feature_guard.cc:182<span style=color:#c7bf54>]</span> This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
</span></span><span style=display:flex><span>To <span style=color:#ef8383>enable</span> the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
</span></span><span style=display:flex><span>2024-09-08 16:54:20.070489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38<span style=color:#c7bf54>]</span> TF-TRT Warning: Could not find TensorRT
</span></span><span style=display:flex><span><span style=color:#d19a66>1021</span> / <span style=color:#d19a66>118287</span> images have no annotations
</span></span><span style=display:flex><span>calib2017 <span style=color:#8a93a5;font-style:italic>#8192: /home/ubuntu/.hailomz/data/coco/train2017/000000171472.jpg: 100%|████████████████████████████████████████████████████████████████████████████████████| 8192/8192 [00:15&lt;00:00, 529.18it/s]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Done converting <span style=color:#d19a66>8192</span> images
</span></span></code></pre></div><h4 id=314-安装-hailo_dataflow_compiler>3.1.4 安装 hailo_dataflow_compiler</h4><ul><li>安装 hailo_dataflow_compiler 依赖</li></ul><p>hailo_dataflow_compiler 用于将其他模型编译为 Hailo 支持的模型；在安装 hailo_dataflow_compiler 之前，需要先安装 pygraphviz，如果通过 hailo_dataflow_compiler 安装可能会提示 <code>fatal error: graphviz/cgraph.h: 没有那个文件或目录</code>，改成用 conda 安装即可</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda install pygraphviz
</span></span></code></pre></div><p>从 <a href=https://hailo.ai/developer-zone/software-downloads/>Developer Zone</a> 下载并安装 hailo_dataflow_compiler</p><p><img src=https://img.hellowood.dev/picture/homelab-tpu-hailo-software-download-hailo-data-compile.png alt=homelab-tpu-hailo-software-download-hailo-data-compile.png></p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install hailo_dataflow_compiler-3.28.0-py3-none-linux_x86_64.whl
</span></span></code></pre></div><h3 id=32-编译模型>3.2 编译模型</h3><p>Hailo 不同硬件的模型不通用，所以需要在编译时通过 <code>--hw-arch</code> 指定硬件类型，以 Hailo8 为例，需要指定 <code>--hw-arch hailo8</code>；如果是 Hailo8L 则指定 <code>--hw-arch hailo8l</code></p><h4 id=321-解析模型>3.2.1 解析模型</h4><p>parse 用于将模型从各种框架解析为 HAR 格式（Hailo Archive）的步骤，HAR 是一个 tar.gz 存档文件，其中包含部署到 Hailo 运行时的图结构和权重的表示形式</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hailomz parse --hw-arch hailo8 --ckpt ./best.onnx yolov8n
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; Start run <span style=color:#c678dd>for</span> network yolov8n ...
</span></span><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; Initializing the runner...
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Translation started on ONNX model yolov8n
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Restored ONNX model yolov8n <span style=color:#c7bf54>(</span>completion time: 00:00:00.04<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Extracted ONNXRuntime meta-data <span style=color:#c678dd>for</span> Hailo model <span style=color:#c7bf54>(</span>completion time: 00:00:00.26<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> NMS structure of yolov8 <span style=color:#c7bf54>(</span>or equivalent architecture<span style=color:#c7bf54>)</span> was detected.
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> In order to use HailoRT post-processing capabilities, these end node names should be used: /model.22/cv2.0/cv2.0.2/Conv /model.22/cv3.0/cv3.0.2/Conv /model.22/cv2.1/cv2.1.2/Conv /model.22/cv3.1/cv3.1.2/Conv /model.22/cv2.2/cv2.2.2/Conv /model.22/cv3.2/cv3.2.2/Conv.
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Start nodes mapped from original model: <span style=color:#98c379>&#39;images&#39;</span>: <span style=color:#98c379>&#39;yolov8n/input_layer1&#39;</span>.
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> End nodes mapped from original model: <span style=color:#98c379>&#39;/model.22/cv2.0/cv2.0.2/Conv&#39;</span>, <span style=color:#98c379>&#39;/model.22/cv3.0/cv3.0.2/Conv&#39;</span>, <span style=color:#98c379>&#39;/model.22/cv2.1/cv2.1.2/Conv&#39;</span>, <span style=color:#98c379>&#39;/model.22/cv3.1/cv3.1.2/Conv&#39;</span>, <span style=color:#98c379>&#39;/model.22/cv2.2/cv2.2.2/Conv&#39;</span>, <span style=color:#98c379>&#39;/model.22/cv3.2/cv3.2.2/Conv&#39;</span>.
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Translation completed on ONNX model yolov8n <span style=color:#c7bf54>(</span>completion time: 00:00:00.67<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Saved HAR to: /home/ubuntu/workspace/hailo/custom-train/data/model/yolov8n.har
</span></span></code></pre></div><h4 id=322-量化模型>3.2.2 量化模型</h4><p>optimize 输入是 Hailo 模型状态下的 HAR 文件（优化前；具有本机权重），输出将是具有量化权重的量化 HAR 文件</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hailomz optimize --hw-arch hailo8 --har ./yolov8n.har yolov8n
</span></span></code></pre></div><p>输出如下；如果这个过程提示 <code>FileNotFoundError: no alls found for requested hw_arch</code>，参考后面问题部分处理</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; Start run <span style=color:#c678dd>for</span> network yolov8n ...
</span></span><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; Initializing the hailo8 runner...
</span></span><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; Preparing calibration data...
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Loading model script commands to yolov8n from /home/ubuntu/anaconda3/envs/hailo/lib/python3.10/site-packages/hailo_model_zoo/cfg/alls/hailo8/base/yolov8n.alls
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Starting Model Optimization
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>warning<span style=color:#c7bf54>]</span> Reducing optimization level to <span style=color:#d19a66>0</span> <span style=color:#c7bf54>(</span>the accuracy won<span style=color:#98c379>&#39;t be optimized and compression won&#39;</span>t be used<span style=color:#c7bf54>)</span> because there&#39;s no available GPU
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>warning<span style=color:#c7bf54>]</span> Running model optimization with zero level of optimization is not recommended <span style=color:#c678dd>for</span> production use and might lead to suboptimal accuracy results
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Model received quantization params from the hn
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Starting Mixed Precision
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Mixed Precision is <span style=color:#c678dd>done</span> <span style=color:#c7bf54>(</span>completion <span style=color:#ef8383>time</span> is 00:00:00.26<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Layer Norm Decomposition skipped
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Starting Stats Collector
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Using dataset with <span style=color:#d19a66>64</span> entries <span style=color:#c678dd>for</span> calibration
</span></span><span style=display:flex><span>Calibration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 <span style=color:#c7bf54>[</span>00:15&lt;00:00,  4.25entries/s<span style=color:#c7bf54>]</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Stats Collector is <span style=color:#c678dd>done</span> <span style=color:#c7bf54>(</span>completion <span style=color:#ef8383>time</span> is 00:00:15.89<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Starting Fix zp_comp Encoding
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Fix zp_comp Encoding is <span style=color:#c678dd>done</span> <span style=color:#c7bf54>(</span>completion <span style=color:#ef8383>time</span> is 00:00:00.00<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> matmul_equalization skipped
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Finetune encoding skipped
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Bias Correction skipped
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Adaround skipped
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Fine Tune skipped
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Layer Noise Analysis skipped
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Model Optimization is <span style=color:#c678dd>done</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Saved HAR to: /home/ubuntu/workspace/hailo/custom-train/data/model/yolov8n.har
</span></span></code></pre></div><h4 id=323-编译模型>3.2.3 编译模型</h4><p>compile 将模型转换为HEF可执行格式</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hailomz compile  yolov8n --hw-arch hailo8 --har ./yolov8n.har
</span></span></code></pre></div><p>输出如下：</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; Start run <span style=color:#c678dd>for</span> network yolov8n ...
</span></span><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; Initializing the hailo8 runner...
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Loading model script commands to yolov8n from /home/ubuntu/anaconda3/envs/hailo/lib/python3.10/site-packages/hailo_model_zoo/cfg/alls/hailo8/base/yolov8n.alls
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> To achieve optimal performance, <span style=color:#ef8383>set</span> the compiler_optimization_level to <span style=color:#63c381>&#34;max&#34;</span> by adding performance_param<span style=color:#c7bf54>(</span><span style=color:#dcaeea>compiler_optimization_level</span><span style=color:#c7bf54>=</span>max<span style=color:#c7bf54>)</span> to the model script. Note that this may increase compilation time.
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Adding an output layer after conv41
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Adding an output layer after conv42
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Adding an output layer after conv52
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Adding an output layer after conv53
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Adding an output layer after conv62
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Adding an output layer after conv63
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Loading network parameters
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>warning<span style=color:#c7bf54>]</span> Output order different size
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Starting Hailo allocation and compilation flow
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Using Single-context flow
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Resources optimization guidelines: Strategy -&gt; GREEDY Objective -&gt; MAX_FPS
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Resources optimization params: <span style=color:#dcaeea>max_control_utilization</span><span style=color:#c7bf54>=</span>75%, <span style=color:#dcaeea>max_compute_utilization</span><span style=color:#c7bf54>=</span>75%, <span style=color:#dcaeea>max_compute_16bit_utilization</span><span style=color:#c7bf54>=</span>75%, max_memory_utilization <span style=color:#c7bf54>(</span>weights<span style=color:#c7bf54>)=</span>75%, <span style=color:#dcaeea>max_input_aligner_utilization</span><span style=color:#c7bf54>=</span>75%, <span style=color:#dcaeea>max_apu_utilization</span><span style=color:#c7bf54>=</span>75%
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Using Single-context flow
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Resources optimization guidelines: Strategy -&gt; GREEDY Objective -&gt; MAX_FPS
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Resources optimization params: <span style=color:#dcaeea>max_control_utilization</span><span style=color:#c7bf54>=</span>75%, <span style=color:#dcaeea>max_compute_utilization</span><span style=color:#c7bf54>=</span>75%, <span style=color:#dcaeea>max_compute_16bit_utilization</span><span style=color:#c7bf54>=</span>75%, max_memory_utilization <span style=color:#c7bf54>(</span>weights<span style=color:#c7bf54>)=</span>75%, <span style=color:#dcaeea>max_input_aligner_utilization</span><span style=color:#c7bf54>=</span>75%, <span style=color:#dcaeea>max_apu_utilization</span><span style=color:#c7bf54>=</span>75%
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Validating context_0 layer by layer <span style=color:#c7bf54>(</span>100%<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +
</span></span><span style=display:flex><span> +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +
</span></span><span style=display:flex><span> +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +
</span></span><span style=display:flex><span> +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +
</span></span><span style=display:flex><span> +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>● Finished
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Solving the allocation <span style=color:#c7bf54>(</span>Mapping<span style=color:#c7bf54>)</span>, <span style=color:#ef8383>time</span> per context: 59m 59s
</span></span><span style=display:flex><span>Context:0/0 Iteration 4: Trying parallel mapping...
</span></span><span style=display:flex><span>          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost
</span></span><span style=display:flex><span> worker0  V          V          V          V          V          V          V          V          V
</span></span><span style=display:flex><span> worker1  *          *          *          *          *          *          *          *          V
</span></span><span style=display:flex><span> worker2  *          *          *          *          *          *          *          *          V
</span></span><span style=display:flex><span> worker3  *          *          *          *          *          *          *          *          V
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  00:05
</span></span><span style=display:flex><span>Reverts on cluster mapping: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span>Reverts on inter-cluster connectivity: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span>Reverts on pre-mapping validation: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span>Reverts on split failed: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Iterations: <span style=color:#d19a66>4</span>
</span></span><span style=display:flex><span>Reverts on cluster mapping: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span>Reverts on inter-cluster connectivity: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span>Reverts on pre-mapping validation: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span>Reverts on split failed: <span style=color:#d19a66>0</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> +-----------+---------------------+---------------------+--------------------+
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | Cluster   | Control Utilization | Compute Utilization | Memory Utilization |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> +-----------+---------------------+---------------------+--------------------+
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_0 | 68.8%               | 40.6%               | 15.6%              |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_1 | 81.3%               | 57.8%               | 37.5%              |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_2 | 81.3%               | 96.9%               | 93%                |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_3 | 50%                 | 56.3%               | 32%                |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_4 | 62.5%               | 45.3%               | 29.7%              |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_5 | 75%                 | 76.6%               | 98.4%              |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_6 | 81.3%               | 56.3%               | 37.5%              |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | cluster_7 | 100%                | 73.4%               | 38.3%              |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> +-----------+---------------------+---------------------+--------------------+
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> | Total     | 75%                 | 62.9%               | 47.8%              |
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> +-----------+---------------------+---------------------+--------------------+
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Successful Mapping <span style=color:#c7bf54>(</span>allocation time: 23s<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Compiling context_0...
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Bandwidth of model inputs: 9.375 Mbps, outputs: 9.22852 Mbps <span style=color:#c7bf54>(</span><span style=color:#c678dd>for</span> a single frame<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Bandwidth of DDR buffers: 0.0 Mbps <span style=color:#c7bf54>(</span><span style=color:#c678dd>for</span> a single frame<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Bandwidth of inter context tensors: 0.0 Mbps <span style=color:#c7bf54>(</span><span style=color:#c678dd>for</span> a single frame<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Building HEF...
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Successful Compilation <span style=color:#c7bf54>(</span>compilation time: 14s<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span><span style=color:#c7bf54>[</span>info<span style=color:#c7bf54>]</span> Saved HAR to: /home/ubuntu/workspace/hailo/custom-train/data/model/yolov8n.har
</span></span><span style=display:flex><span>&lt;Hailo Model Zoo INFO&gt; HEF file written to yolov8n.hef
</span></span></code></pre></div><h2 id=4-验证模型>4. 验证模型</h2><h3 id=41-使用-hailortcli-检测>4.1 使用 hailortcli 检测</h3><p>在编译完成后，会生成 <code>.hef</code> 格式的模型文件，此时可以用 <code>hailortcli</code> 解析模型的信息</p><h4 id=411-安装-hailort>4.1.1 安装 HailoRT</h4><p>从 <a href=https://hailo.ai/developer-zone/software-downloads/>Developer Zone</a> 下载并安装 HailoRT，通过 dpkg 安装</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo dpkg --install hailort_4.18.0_amd64.deb
</span></span></code></pre></div><p><img src=https://img.hellowood.dev/picture/homelab-tpu-hailo-software-download-page.png alt=homelab-tpu-hailo-software-download-page.png></p><h4 id=412-检测模型信息>4.1.2 检测模型信息</h4><ul><li>获取模型信息</li></ul><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hailortcli parse-hef ./yolov8n.hef
</span></span></code></pre></div><p>信息如下：</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Architecture HEF was compiled <span style=color:#c678dd>for</span>: HAILO8
</span></span><span style=display:flex><span>Network group name: yolov8n, Single Context
</span></span><span style=display:flex><span>    Network name: yolov8n/yolov8n
</span></span><span style=display:flex><span>        VStream infos:
</span></span><span style=display:flex><span>            Input  yolov8n/input_layer1 UINT8, NHWC<span style=color:#c7bf54>(</span>640x640x3<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span>            Output yolov8n/yolov8_nms_postprocess FLOAT32, HAILO NMS<span style=color:#c7bf54>(</span>number of classes: 80, maximum bounding boxes per class: 100, maximum frame size: 160320<span style=color:#c7bf54>)</span>
</span></span><span style=display:flex><span>            Operation:
</span></span><span style=display:flex><span>                Op YOLOV8
</span></span><span style=display:flex><span>                Name: YOLOV8-Post-Process
</span></span><span style=display:flex><span>                Score threshold: 0.200
</span></span><span style=display:flex><span>                IoU threshold: 0.70
</span></span><span style=display:flex><span>                Classes: <span style=color:#d19a66>80</span>
</span></span><span style=display:flex><span>                Cross classes: <span style=color:#ef8383>false</span>
</span></span><span style=display:flex><span>                Max bboxes per class: <span style=color:#d19a66>100</span>
</span></span><span style=display:flex><span>                Image height: <span style=color:#d19a66>640</span>
</span></span><span style=display:flex><span>                Image width: <span style=color:#d19a66>640</span>
</span></span></code></pre></div><ul><li>运行模型</li></ul><p>使用 hailortcli 运行模型，查看模型性能</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hailortcli run /home/ubuntu/workspace/project/hailo/model/yolov8n.hef --measure-temp
</span></span></code></pre></div><p>运行结果表明可以处理的图片帧率为 184.58</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Running streaming inference <span style=color:#c7bf54>(</span>/home/ubuntu/workspace/project/hailo/model/yolov8n.hef<span style=color:#c7bf54>)</span>:
</span></span><span style=display:flex><span>  Transform data: <span style=color:#ef8383>true</span>
</span></span><span style=display:flex><span>    Type:      auto
</span></span><span style=display:flex><span>    Quantized: <span style=color:#ef8383>true</span>
</span></span><span style=display:flex><span>Network yolov8n/yolov8n: 100% | <span style=color:#d19a66>924</span> | FPS: 184.58 | ETA: 00:00:00
</span></span><span style=display:flex><span>&gt; Inference result:
</span></span><span style=display:flex><span> Network group: yolov8n
</span></span><span style=display:flex><span>    Frames count: <span style=color:#d19a66>924</span>
</span></span><span style=display:flex><span>    FPS: 184.59
</span></span><span style=display:flex><span>    Send Rate: 1814.58 Mbit/s
</span></span><span style=display:flex><span>    Recv Rate: 1803.24 Mbit/s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  Device: 0000:04:00.0
</span></span><span style=display:flex><span>    Minimum chip temperature: 35.3433C
</span></span><span style=display:flex><span>    Average chip temperature: 38.2565C
</span></span><span style=display:flex><span>    Maximum chip temperature: 39.289C
</span></span></code></pre></div><h3 id=42-使用-python-进行对象检测>4.2 使用 Python 进行对象检测</h3><p>使用 Hailo 提供的 Demo，使用编译后的模型进行对象检测</p><h4 id=421-下载-demo>4.2.1 下载 Demo</h4><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git clone https://github.com/hailo-ai/Hailo-Application-Code-Examples.git
</span></span></code></pre></div><h4 id=422-运行对象检测-demo>4.2.2 运行对象检测 Demo</h4><p>进入到对象检测 Demo 路径下</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#ef8383>cd</span> Hailo-Application-Code-Examples/runtime/python/object_detection
</span></span></code></pre></div><p>运行 Demo</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python object_detection.py -n /home/ubuntu/workspace/project/hailo/model/yolov8n.hef -i ./zidane.jpg -l coco.txt
</span></span></code></pre></div><p>会提示将标注后到图片输出到指定的路径</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>2024-09-08 17:42:27.549 | INFO     | __main__:infer:175 - Inference was successful! Results have been saved in output_images
</span></span></code></pre></div><h2 id=问题>问题</h2><ol><li>FileNotFoundError: no alls found for requested hw_arch</li></ol><p>这个错误是因为没有模型对应的 alls 文件，这个文件在 <a href=https://github.com/hailo-ai/hailo_model_zoo/>https://github.com/hailo-ai/hailo_model_zoo/</a> 仓库可以找到，路径是 <code>hailo_model_zoo/cfg/alls</code>；可以直接 clone 仓库到本地，然后将文件复制到虚拟环境中</p><p>因为还依赖 <code>postprocess_config</code>目录下的 <code>xxx_nms_config.json</code> 文件，所以直接复制 <code>hailo_model_zoo/cfg</code> 目录</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git clone https://github.com/hailo-ai/hailo_model_zoo.git
</span></span><span style=display:flex><span><span style=color:#ef8383>cd</span> hailo_model_zoo
</span></span><span style=display:flex><span>rm -rf /home/ubuntu/anaconda3/envs/hailo/lib/python3.10/site-packages/hailo_model_zoo/cfg
</span></span><span style=display:flex><span>cp -r hailo_model_zoo/hailo_model_zoo/cfg /home/ubuntu/anaconda3/envs/hailo/lib/python3.10/site-packages/hailo_model_zoo/cfg
</span></span></code></pre></div><ol start=2><li>安装 pygraphviz 失败，提示 <code>fatal error: graphviz/cgraph.h: 没有那个文件或目录</code></li></ol><p>改用 conda 安装: <code>conda install pygraphviz</code> 即可</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>      gcc -pthread -B /home/ubuntu/anaconda3/envs/hailo-zoo/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ubuntu/anaconda3/envs/hailo-zoo/include -fPIC -O2 -isystem /home/ubuntu/anaconda3/envs/hailo-zoo/include -fPIC -DSWIG_PYTHON_STRICT_BYTE_CHAR -I/home/ubuntu/anaconda3/envs/hailo-zoo/include/python3.10 -c pygraphviz/graphviz_wrap.c -o build/temp.linux-x86_64-cpython-310/pygraphviz/graphviz_wrap.o
</span></span><span style=display:flex><span>      pygraphviz/graphviz_wrap.c:9: warning: <span style=color:#63c381>&#34;SWIG_PYTHON_STRICT_BYTE_CHAR&#34;</span> redefined
</span></span><span style=display:flex><span>          <span style=color:#d19a66>9</span> | <span style=color:#8a93a5;font-style:italic>#define SWIG_PYTHON_STRICT_BYTE_CHAR</span>
</span></span><span style=display:flex><span>            |
</span></span><span style=display:flex><span>      &lt;command-line&gt;: note: this is the location of the previous definition
</span></span><span style=display:flex><span>      pygraphviz/graphviz_wrap.c:3023:10: fatal error: graphviz/cgraph.h: 没有那个文件或目录
</span></span><span style=display:flex><span>       <span style=color:#d19a66>3023</span> | <span style=color:#8a93a5;font-style:italic>#include &#34;graphviz/cgraph.h&#34;</span>
</span></span><span style=display:flex><span>            |          ^~~~~~~~~~~~~~~~~~~
</span></span><span style=display:flex><span>      compilation terminated.
</span></span><span style=display:flex><span>      error: <span style=color:#ef8383>command</span> <span style=color:#98c379>&#39;/usr/bin/gcc&#39;</span> failed with <span style=color:#ef8383>exit</span> code <span style=color:#d19a66>1</span>
</span></span><span style=display:flex><span>      <span style=color:#c7bf54>[</span>end of output<span style=color:#c7bf54>]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  note: This error originates from a subprocess, and is likely not a problem with pip.
</span></span><span style=display:flex><span>  ERROR: Failed building wheel <span style=color:#c678dd>for</span> pygraphviz
</span></span><span style=display:flex><span>Failed to build pygraphviz
</span></span><span style=display:flex><span>ERROR: ERROR: Failed to build installable wheels <span style=color:#c678dd>for</span> some pyproject.toml based projects <span style=color:#c7bf54>(</span>pygraphviz<span style=color:#c7bf54>)</span>
</span></span></code></pre></div><ol start=3><li>FileNotFoundError: Couldn&rsquo;t find dataset in /home/ubuntu/.hailomz/data/models_files/coco/2021-06-18/coco_calib2017.tfrecord</li></ol><p>通过 创建的 tfrecord 的路径可能和实际不一样，如要求的路径是 <code>~/.hailomz/data/models_files/coco/2021-06-18/coco_calib2017.tfrecord</code>，实际的路径是 <code>~/.hailomz/data/models_files/coco/2023-08-03/coco_calib2017.tfrecord</code>，通过指定 <code>clibpath</code> 参数即可:</p><div class=highlight><pre tabindex=0 style=color:#b0c4de;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hailomz optimize --hw-arch hailo8l --har ./yolov8n.har yolov8n --calib-path ~/.hailomz/data/models_files/coco/2023-08-03/coco_calib2017.tfrecord
</span></span></code></pre></div></div><div class=prev-next></div><svg id="btt-button" class="arrow-logo" height="1em" viewBox="0 0 384 512" onclick="scrollToTop()" title="Go to top"><path d="M177 159.7l136 136c9.4 9.4 9.4 24.6.0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9.0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9.0L7 329.7c-9.4-9.4-9.4-24.6.0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/></svg>
<script>let backToTopButton=document.getElementById("btt-button");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?backToTopButton.style.display="block":backToTopButton.style.display="none"}function scrollToTop(){window.scrollTo(0,0)}</script><div id=comments><script src=https://utteranc.es/client.js repo=helloworlde/helloworlde.github.io issue-term=title theme=github-light crossorigin=anonymous async></script></div></div></main><footer class=footer><span>&copy; 2024 hellowood.dev</span>
<span>Made with &#10084;&#65039; using <a target=_blank href=https://github.com/gokarna-theme/gokarna-hugo>Gokarna</a></span></footer></body></html>