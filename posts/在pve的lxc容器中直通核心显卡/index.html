<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>在PVE的LXC容器中直通核心显卡</title><meta charset=utf-8><meta name=description content="Ladder@在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中
安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常
lspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常
ls /dev/dri/ by-path card0	renderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装
创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 &ldquo;无特权容器&rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可"><meta name=author content="HelloWood"><link rel=canonical href=https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/><meta name=google-site-verification content="G-3MSGPYTHPZ"><link rel=alternate type=application/rss+xml href=https://blog.hellowood.dev/index.xml title=HelloWood><script async src="https://www.googletagmanager.com/gtag/js?id=G-3MSGPYTHPZ"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-3MSGPYTHPZ",{anonymize_ip:!1})}</script><script async defer data-website-id=7a9034de-0ce7-4756-942a-829e6cd22301 src=https://umami.hellowood.dev/script.js></script><meta property="og:title" content="在PVE的LXC容器中直通核心显卡"><meta property="og:description" content="在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中
安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常
lspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常
ls /dev/dri/ by-path card0	renderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装
创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 &ldquo;无特权容器&rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-09T17:53:36+08:00"><meta property="article:modified_time" content="2023-09-09T17:53:36+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="在PVE的LXC容器中直通核心显卡"><meta name=twitter:description content="在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中
安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常
lspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常
ls /dev/dri/ by-path card0	renderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装
创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 &ldquo;无特权容器&rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://blog.hellowood.dev/posts/"},{"@type":"ListItem","position":3,"name":"在PVE的LXC容器中直通核心显卡","item":"https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"在PVE的LXC容器中直通核心显卡","name":"在PVE的LXC容器中直通核心显卡","description":"在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中\n安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常\nlspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常\nls /dev/dri/ by-path card0\trenderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装\n创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 \u0026ldquo;无特权容器\u0026rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可","keywords":["LXC","Proxmox","HomeLab"],"articleBody":"在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中\n安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常\nlspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常\nls /dev/dri/ by-path card0\trenderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装\n创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 “无特权容器” 的勾选，模板选择 CentOS 或 Ubuntu 等均可\n创建完成后，即可看到容器的 ID，即VMID，这里是 104\n修改核心显卡直通 修改核心显卡直通，需要使用 PVE 宿主机的命令行修改 LXC 容器的配置文件\n添加核心显卡直通 使用 nano 编辑容器对应的配置文件，容器ID 104对应的文件是 104.conf，路径是 /etc/pve/lxc/\nnano /etc/pve/lxc/104.conf 打开后默认的配置如下：\narch: amd64 cores: 2 hostname: frigate memory: 2048 net0: name=eth0,bridge=vmbr0,firewall=1,hwaddr=A6:43:11:F3:EE:78,ip=dhcp,type=veth ostype: ubuntu rootfs: local-lvm:vm-104-disk-0,size=8G swap: 512 需要添加以下内容\nlxc.apparmor.profile: unconfined lxc.cgroup.devices.allow: a lxc.cap.drop: lxc.cgroup2.devices.allow: c 226:0 rwm lxc.cgroup2.devices.allow: c 226:128 rwm lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file 这些配置参数是针对 Linux 容器（通常是 LXC 容器）的一些安全和资源控制设置，用于限制容器内部的行为和访问。以下是每个配置项的作用解释：\nlxc.apparmor.profile: unconfined：该配置指定了 AppArmor（应用程序安全性配置框架）的配置文件名称，这里设置为 “unconfined”，用于允许容器内的进程具有更高的系统权限\nlxc.cgroup.devices.allow: a： 允许容器内的进程访问所有的 cgroup 设备。\nlxc.cap.drop: 此配置项为空，容器内的进程将继承主机系统的默认能力设置。\nlxc.cgroup2.devices.allow: c 226:0 rwm 和 lxc.cgroup2.devices.allow: c 226:128 rwm： 允许容器内的进程对设备号为 226:0 和 226:128 的字符设备节点拥有读、写和映射（rwm）的权限。用于允许容器内的进程访问特定的设备，如图形加速设备。\nlxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file 和 lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file：将主机系统上的两个设备节点 /dev/dri/card0 和 /dev/dri/renderD128 挂载到容器内的相同位置，用于允许容器内的应用程序访问图形硬件加速功能，以便执行图形相关的任务\n修改完成后保存，启动 LXC 容器\n检查核显 等容器启动成功后，进入容器，使用命令行检查 /dev/dri 路径下挂载的文件，card0和 renderD128 都正常\nls /dev/dri/ card0 renderD128 查看 PCI 也能看到核心显卡，说明挂载成功\nlspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 将显卡挂载到 Docker 容器中 使用 docker-compose 部署 frigate，在配置文件中将设备 /dev/dri/renderD128 挂载到容器中即可\nservices: frigate: container_name: frigate privileged: true restart: unless-stopped image: ghcr.io/blakeblackshear/frigate:stable shm_size: \"256mb\" devices: - /dev/dri/renderD128 这样，容器就可以正常使用核显进行 ffmpeg 硬件加速了\n挂载 TUN 设备 如果你需要在 LXC 容器中使用 WireGuard/ TailScale/Clash 等依赖 TUN 网络的设备，还需要添加以下内容：\nlxc.cgroup2.devices.allow: c 10:200 rwm lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file 否则会报错，提示找不到 Socket，这是因为 LXC 容器默认不会挂载 TUN 设备，所以无法访问\nfailed to connect to local tailscaled (which appears to be running as tailscaled, pid 94512). Got error: Failed to connect to local Tailscale daemon for /localapi/v0/status; systemd tailscaled.service not running. Error: dial unix /var/run/tailscale/tailscaled.sock: connect: no such file or directory ","wordCount":"299","inLanguage":"en","datePublished":"2023-09-09T17:53:36+08:00","dateModified":"2023-09-09T17:53:36+08:00","author":{"@type":"Person","name":"HelloWood"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/"},"publisher":{"@type":"Organization","name":"HelloWood","logo":{"@type":"ImageObject","url":"https://blog.hellowood.dev/favicon.ico"}}}</script><link rel=icon href=/images/avatar.png sizes=16x16><link rel=apple-touch-icon href=/images/avatar.png><link rel=manifest href=/images/avatar.png><link rel=stylesheet href=https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css><link rel=stylesheet href=/css/main.min.f8020eba33d585b82c30b2a1ceb0d4c4e8e41fb6d8843d07d8ad056da8712972.css integrity="sha256-+AIOujPVhbgsMLKhzrDUxOjkH7bYhD0H2K0FbahxKXI=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.872dfd2cd00064018a833a6e8e77a0fbf8fbac159546f2f205d4dad79a5d8e15.js></script>
<script>hljs.highlightAll()</script><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand href=/>HOME</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link href=/posts>Blog</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/tags>Tags</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/archives>Archive</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=https://umami.hellowood.dev/share/lab/Blog>Dashboard</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link href=https://github.com/helloworlde><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>在PVE的LXC容器中直通核心显卡</h1></header><p><small>September 9, 2023&nbsp;· 299 words&nbsp;· 2 min</small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#安装核显驱动>安装核显驱动</a></li><li><a href=#创建-lxc-容器>创建 LXC 容器</a></li><li><a href=#修改核心显卡直通>修改核心显卡直通</a></li><li><a href=#检查核显>检查核显</a></li><li><a href=#将显卡挂载到-docker-容器中>将显卡挂载到 Docker 容器中</a></li><li><a href=#挂载-tun-设备>挂载 TUN 设备</a></li></ul></nav></div><section class=blog-content><h1 id=在-proxmoxve-的-lxc-容器中直通核心显卡>在 ProxmoxVE 的 LXC 容器中直通核心显卡</h1><p>在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 <a href=https://frigate.video/>frigate</a> 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中</p><h2 id=安装核显驱动>安装核显驱动</h2><ul><li>查看设备</li></ul><p>如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>lspci | grep VGA
</span></span><span style=display:flex><span>00:02.0 VGA compatible controller: Intel Corporation JasperLake <span style=color:#f92672>[</span>UHD Graphics<span style=color:#f92672>]</span> <span style=color:#f92672>(</span>rev 01<span style=color:#f92672>)</span>
</span></span></code></pre></div><ul><li>查看驱动</li></ul><p>可以看到 card0 和 renderD128 都存在，说明驱动正常</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls /dev/dri/
</span></span><span style=display:flex><span>by-path  card0	renderD128
</span></span></code></pre></div><p>通常不需要安装驱动，如果设备没有正确识别，可以参考 <a href=https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps>https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps</a> 进行安装</p><h2 id=创建-lxc-容器>创建 LXC 容器</h2><p>如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 &ldquo;无特权容器&rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可</p><p><img src=https://hellowoodes.oss-cn-beijing.aliyuncs.com/picture/homelab-pve-lxc-intel-graphics-mount-1.png alt=homelab-pve-lxc-intel-graphics-mount-1.png></p><p><img src=https://hellowoodes.oss-cn-beijing.aliyuncs.com/picture/homelab-pve-lxc-intel-graphics-mount-2.png alt=homelab-pve-lxc-intel-graphics-mount-2.png></p><p>创建完成后，即可看到容器的 ID，即VMID，这里是 104</p><h2 id=修改核心显卡直通>修改核心显卡直通</h2><p>修改核心显卡直通，需要使用 PVE 宿主机的命令行修改 LXC 容器的配置文件</p><ul><li>添加核心显卡直通</li></ul><p>使用 nano 编辑容器对应的配置文件，容器ID 104对应的文件是 <code>104.conf</code>，路径是 <code>/etc/pve/lxc/</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>nano /etc/pve/lxc/104.conf
</span></span></code></pre></div><p>打开后默认的配置如下：</p><pre tabindex=0><code class=language-dsconfig data-lang=dsconfig>arch: amd64
cores: 2
hostname: frigate
memory: 2048
net0: name=eth0,bridge=vmbr0,firewall=1,hwaddr=A6:43:11:F3:EE:78,ip=dhcp,type=veth
ostype: ubuntu
rootfs: local-lvm:vm-104-disk-0,size=8G
swap: 512
</code></pre><p>需要添加以下内容</p><pre tabindex=0><code class=language-dsconfig data-lang=dsconfig>lxc.apparmor.profile: unconfined
lxc.cgroup.devices.allow: a
lxc.cap.drop:
lxc.cgroup2.devices.allow: c 226:0 rwm
lxc.cgroup2.devices.allow: c 226:128 rwm
lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file
lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file
</code></pre><p>这些配置参数是针对 Linux 容器（通常是 LXC 容器）的一些安全和资源控制设置，用于限制容器内部的行为和访问。以下是每个配置项的作用解释：</p><p><code>lxc.apparmor.profile: unconfined</code>：该配置指定了 AppArmor（应用程序安全性配置框架）的配置文件名称，这里设置为 &ldquo;unconfined&rdquo;，用于允许容器内的进程具有更高的系统权限</p><p><code>lxc.cgroup.devices.allow: a</code>： 允许容器内的进程访问所有的 cgroup 设备。</p><p><code>lxc.cap.drop</code>: 此配置项为空，容器内的进程将继承主机系统的默认能力设置。</p><p><code>lxc.cgroup2.devices.allow: c 226:0 rwm</code> 和 <code>lxc.cgroup2.devices.allow: c 226:128 rwm</code>： 允许容器内的进程对设备号为 <code>226:0</code> 和 <code>226:128</code> 的字符设备节点拥有读、写和映射（rwm）的权限。用于允许容器内的进程访问特定的设备，如图形加速设备。</p><p><code>lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file</code> 和
<code>lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file</code>：将主机系统上的两个设备节点 <code>/dev/dri/card0</code> 和 <code>/dev/dri/renderD128</code> 挂载到容器内的相同位置，用于允许容器内的应用程序访问图形硬件加速功能，以便执行图形相关的任务</p><p>修改完成后保存，启动 LXC 容器</p><h2 id=检查核显>检查核显</h2><p>等容器启动成功后，进入容器，使用命令行检查 <code>/dev/dri</code> 路径下挂载的文件，<code>card0</code>和 <code>renderD128</code> 都正常</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls /dev/dri/
</span></span><span style=display:flex><span>card0  renderD128
</span></span></code></pre></div><p>查看 PCI 也能看到核心显卡，说明挂载成功</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>lspci | grep VGA
</span></span><span style=display:flex><span>00:02.0 VGA compatible controller: Intel Corporation JasperLake <span style=color:#f92672>[</span>UHD Graphics<span style=color:#f92672>]</span> <span style=color:#f92672>(</span>rev 01<span style=color:#f92672>)</span>
</span></span></code></pre></div><h2 id=将显卡挂载到-docker-容器中>将显卡挂载到 Docker 容器中</h2><p>使用 docker-compose 部署 frigate，在配置文件中将设备 <code>/dev/dri/renderD128</code> 挂载到容器中即可</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>frigate</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>frigate</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>privileged</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>restart</span>: <span style=color:#ae81ff>unless-stopped</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>ghcr.io/blakeblackshear/frigate:stable</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>shm_size</span>: <span style=color:#e6db74>&#34;256mb&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>devices</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>/dev/dri/renderD128</span>
</span></span></code></pre></div><p>这样，容器就可以正常使用核显进行 ffmpeg 硬件加速了</p><h2 id=挂载-tun-设备>挂载 TUN 设备</h2><p>如果你需要在 LXC 容器中使用 WireGuard/ TailScale/Clash 等依赖 TUN 网络的设备，还需要添加以下内容：</p><pre tabindex=0><code class=language-dsconfig data-lang=dsconfig>lxc.cgroup2.devices.allow: c 10:200 rwm
lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file
</code></pre><p>否则会报错，提示找不到 Socket，这是因为 LXC 容器默认不会挂载 TUN 设备，所以无法访问</p><pre tabindex=0><code>failed to connect to local tailscaled (which appears to be running as tailscaled, pid 94512). Got error: Failed to connect to local Tailscale daemon for /localapi/v0/status; systemd tailscaled.service not running. Error: dial unix /var/run/tailscale/tailscaled.sock: connect: no such file or directory
</code></pre></section><div class=paginator><a class=next href=https://blog.hellowood.dev/posts/%E4%BD%BF%E7%94%A8arpl%E5%9C%A8pve%E4%B8%8A%E5%AE%89%E8%A3%85%E9%BB%91%E7%BE%A4%E6%99%96/><span>使用arpl在PVE上安装黑群晖</span><span>&nbsp;&nbsp;&rarr;</span></a></div></article></div><footer class=footer><p>&copy; 2023 <a href=https://blog.hellowood.dev>HelloWood</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-up"><line x1="12" y1="19" x2="12" y2="5"/><polyline points="5 12 12 5 19 12"/></svg></a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>