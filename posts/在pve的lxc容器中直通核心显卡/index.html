<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>在PVE的LXC容器中直通核心显卡</title>
<meta charset=utf-8><meta name=description content="Ladder@在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中
安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常
lspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常
ls /dev/dri/ by-path card0	renderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装
创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 &ldquo;无特权容器&rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可"><meta name=author content="HelloWood"><link rel=canonical href=https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/><meta name=google-site-verification content="G-3MSGPYTHPZ"><link rel=alternate type=application/rss+xml href=https://blog.hellowood.dev//index.xml title=HelloWood><script async src="https://www.googletagmanager.com/gtag/js?id=G-3MSGPYTHPZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-3MSGPYTHPZ")}</script><script async defer data-website-id=7a9034de-0ce7-4756-942a-829e6cd22301 src=https://umami.hellowood.dev/script.js></script><script defer data-cf-beacon='{"token": "b2e481d136dc428c8c96c8673e2a04cf"}' src=https://static.cloudflareinsights.com/beacon.min.js></script><meta property="og:url" content="https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/"><meta property="og:site_name" content="HelloWood"><meta property="og:title" content="在PVE的LXC容器中直通核心显卡"><meta property="og:description" content="在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中
安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常
lspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常
ls /dev/dri/ by-path card0	renderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装
创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 “无特权容器” 的勾选，模板选择 CentOS 或 Ubuntu 等均可"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-09T17:53:36+08:00"><meta property="article:modified_time" content="2023-09-09T17:53:36+08:00"><meta property="article:tag" content="LXC"><meta property="article:tag" content="Proxmox"><meta property="article:tag" content="HomeLab"><meta name=twitter:card content="summary"><meta name=twitter:title content="在PVE的LXC容器中直通核心显卡"><meta name=twitter:description content="在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中
安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常
lspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常
ls /dev/dri/ by-path card0	renderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装
创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 “无特权容器” 的勾选，模板选择 CentOS 或 Ubuntu 等均可"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.hellowood.dev/posts/"},{"@type":"ListItem","position":2,"name":"在PVE的LXC容器中直通核心显卡","item":"https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"在PVE的LXC容器中直通核心显卡","name":"在PVE的LXC容器中直通核心显卡","description":"在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中\n安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常\nlspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常\nls /dev/dri/ by-path card0\trenderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装\n创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 \u0026ldquo;无特权容器\u0026rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可","keywords":["LXC","Proxmox","HomeLab"],"articleBody":"在 ProxmoxVE 的 LXC 容器中直通核心显卡 在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 frigate 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中\n安装核显驱动 查看设备 如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常\nlspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 查看驱动 可以看到 card0 和 renderD128 都存在，说明驱动正常\nls /dev/dri/ by-path card0\trenderD128 通常不需要安装驱动，如果设备没有正确识别，可以参考 https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps 进行安装\n创建 LXC 容器 如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 “无特权容器” 的勾选，模板选择 CentOS 或 Ubuntu 等均可\n创建完成后，即可看到容器的 ID，即VMID，这里是 104\n修改核心显卡直通 修改核心显卡直通，需要使用 PVE 宿主机的命令行修改 LXC 容器的配置文件\n添加核心显卡直通 使用 nano 编辑容器对应的配置文件，容器ID 104对应的文件是 104.conf，路径是 /etc/pve/lxc/\nnano /etc/pve/lxc/104.conf 打开后默认的配置如下：\narch: amd64 cores: 2 hostname: frigate memory: 2048 net0: name=eth0,bridge=vmbr0,firewall=1,hwaddr=A6:43:11:F3:EE:78,ip=dhcp,type=veth ostype: ubuntu rootfs: local-lvm:vm-104-disk-0,size=8G swap: 512 需要添加以下内容\nlxc.apparmor.profile: unconfined lxc.cgroup.devices.allow: a lxc.cap.drop: lxc.cgroup2.devices.allow: c 226:0 rwm lxc.cgroup2.devices.allow: c 226:128 rwm lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file 这些配置参数是针对 Linux 容器（通常是 LXC 容器）的一些安全和资源控制设置，用于限制容器内部的行为和访问。以下是每个配置项的作用解释：\nlxc.apparmor.profile: unconfined：该配置指定了 AppArmor（应用程序安全性配置框架）的配置文件名称，这里设置为 “unconfined”，用于允许容器内的进程具有更高的系统权限\nlxc.cgroup.devices.allow: a： 允许容器内的进程访问所有的 cgroup 设备。\nlxc.cap.drop: 此配置项为空，容器内的进程将继承主机系统的默认能力设置。\nlxc.cgroup2.devices.allow: c 226:0 rwm 和 lxc.cgroup2.devices.allow: c 226:128 rwm： 允许容器内的进程对设备号为 226:0 和 226:128 的字符设备节点拥有读、写和映射（rwm）的权限。用于允许容器内的进程访问特定的设备，如图形加速设备。\nlxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file 和 lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file：将主机系统上的两个设备节点 /dev/dri/card0 和 /dev/dri/renderD128 挂载到容器内的相同位置，用于允许容器内的应用程序访问图形硬件加速功能，以便执行图形相关的任务\n修改完成后保存，启动 LXC 容器\n检查核显 等容器启动成功后，进入容器，使用命令行检查 /dev/dri 路径下挂载的文件，card0和 renderD128 都正常\nls /dev/dri/ card0 renderD128 查看 PCI 也能看到核心显卡，说明挂载成功\nlspci | grep VGA 00:02.0 VGA compatible controller: Intel Corporation JasperLake [UHD Graphics] (rev 01) 将显卡挂载到 Docker 容器中 使用 docker-compose 部署 frigate，在配置文件中将设备 /dev/dri/renderD128 挂载到容器中即可\nservices: frigate: container_name: frigate privileged: true restart: unless-stopped image: ghcr.io/blakeblackshear/frigate:stable shm_size: \"256mb\" devices: - /dev/dri/renderD128 这样，容器就可以正常使用核显进行 ffmpeg 硬件加速了\n挂载 TUN 设备 如果你需要在 LXC 容器中使用 WireGuard/ TailScale/Clash 等依赖 TUN 网络的设备，还需要添加以下内容：\nlxc.cgroup2.devices.allow: c 10:200 rwm lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file 否则会报错，提示找不到 Socket，这是因为 LXC 容器默认不会挂载 TUN 设备，所以无法访问\nfailed to connect to local tailscaled (which appears to be running as tailscaled, pid 94512). Got error: Failed to connect to local Tailscale daemon for /localapi/v0/status; systemd tailscaled.service not running. Error: dial unix /var/run/tailscale/tailscaled.sock: connect: no such file or directory ","wordCount":"299","inLanguage":"en","datePublished":"2023-09-09T17:53:36+08:00","dateModified":"2023-09-09T17:53:36+08:00","author":{"@type":"Person","name":"HelloWood"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/"},"publisher":{"@type":"Organization","name":"HelloWood","logo":{"@type":"ImageObject","url":"https://blog.hellowood.dev/favicon.ico"}}}</script><link rel=icon href=/images/avatar.png sizes=16x16><link rel=apple-touch-icon href=/images/avatar.png><link rel=manifest href=/images/avatar.png><link rel=stylesheet href=https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css><link rel=stylesheet href=/css/main.min.7f82854fa0e999ec07c4835d3029de9f484030e254b80d470b3ca48eb934720e.css integrity="sha256-f4KFT6DpmewHxINdMCnen0hAMOJUuA1HCzykjrk0cg4=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.c607d6febd16934a82eb61d3a896ed9d869f54373cc63ce95864ed5488fe3128.js></script><script>hljs.highlightAll()</script><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><meta name=google-adsense-account content="ca-pub-3401351766168985"><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","jtbhx98g62")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3401351766168985" crossorigin=anonymous></script><script defer src=https://analytics.us.umami.is/script.js data-website-id=73ff1c8c-9938-43cf-81af-e77e26b0cca3></script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand data-umami-event=navigation-brand href=/>HOME
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Blog href=/posts>Blog</a></li><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Tags href=/tags>Tags</a></li><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Archive href=/archives>Archive</a></li><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Dashboard href=https://umami.hellowood.dev/share/lab/Blog>Dashboard</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link data-umami-event=navigation-social href=https://github.com/helloworlde><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button data-umami-event=toggle-theme aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span>
<span class=toggle-light><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>在PVE的LXC容器中直通核心显卡</h1></header><p><small>September 9, 2023&nbsp;· 299 words&nbsp;· 2 min</small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#安装核显驱动>安装核显驱动</a></li><li><a href=#创建-lxc-容器>创建 LXC 容器</a></li><li><a href=#修改核心显卡直通>修改核心显卡直通</a></li><li><a href=#检查核显>检查核显</a></li><li><a href=#将显卡挂载到-docker-容器中>将显卡挂载到 Docker 容器中</a></li><li><a href=#挂载-tun-设备>挂载 TUN 设备</a></li></ul></nav></div><section class=blog-content><h1 id=在-proxmoxve-的-lxc-容器中直通核心显卡>在 ProxmoxVE 的 LXC 容器中直通核心显卡</h1><p>在 ProxmoxVE 平台中使用 LXC 容器使用 Docker 部署 <a href=https://frigate.video/>frigate</a> 时(或其他需要GPU的容器如Jellyfin等)，需要使用 GPU 对 ffmpeg 进行加速，因此需要将宿主机 N5105 的核心显卡挂载到 LXC 容器到 Docker 容器中</p><h2 id=安装核显驱动>安装核显驱动</h2><ul><li>查看设备</li></ul><p>如果能够看到 PCI 设备中包含核心显卡，说明设备识别正常</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>lspci | grep VGA
</span></span><span style=display:flex><span>00:02.0 VGA compatible controller: Intel Corporation JasperLake <span style=color:#f92672>[</span>UHD Graphics<span style=color:#f92672>]</span> <span style=color:#f92672>(</span>rev 01<span style=color:#f92672>)</span>
</span></span></code></pre></div><ul><li>查看驱动</li></ul><p>可以看到 card0 和 renderD128 都存在，说明驱动正常</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls /dev/dri/
</span></span><span style=display:flex><span>by-path  card0	renderD128
</span></span></code></pre></div><p>通常不需要安装驱动，如果设备没有正确识别，可以参考 <a href=https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps>https://dgpu-docs.intel.com/driver/installation.html#ubuntu-install-steps</a> 进行安装</p><h2 id=创建-lxc-容器>创建 LXC 容器</h2><p>如图，在 PVE的控制界面，选择创建 CT 容器；配置中取消 &ldquo;无特权容器&rdquo; 的勾选，模板选择 CentOS 或 Ubuntu 等均可</p><p><img alt=homelab-pve-lxc-intel-graphics-mount-1.png src=https://img.hellowood.dev/picture/homelab-pve-lxc-intel-graphics-mount-1.png></p><p><img alt=homelab-pve-lxc-intel-graphics-mount-2.png src=https://img.hellowood.dev/picture/homelab-pve-lxc-intel-graphics-mount-2.png></p><p>创建完成后，即可看到容器的 ID，即VMID，这里是 104</p><h2 id=修改核心显卡直通>修改核心显卡直通</h2><p>修改核心显卡直通，需要使用 PVE 宿主机的命令行修改 LXC 容器的配置文件</p><ul><li>添加核心显卡直通</li></ul><p>使用 nano 编辑容器对应的配置文件，容器ID 104对应的文件是 <code>104.conf</code>，路径是 <code>/etc/pve/lxc/</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>nano /etc/pve/lxc/104.conf
</span></span></code></pre></div><p>打开后默认的配置如下：</p><pre tabindex=0><code class=language-dsconfig data-lang=dsconfig>arch: amd64
cores: 2
hostname: frigate
memory: 2048
net0: name=eth0,bridge=vmbr0,firewall=1,hwaddr=A6:43:11:F3:EE:78,ip=dhcp,type=veth
ostype: ubuntu
rootfs: local-lvm:vm-104-disk-0,size=8G
swap: 512
</code></pre><p>需要添加以下内容</p><pre tabindex=0><code class=language-dsconfig data-lang=dsconfig>lxc.apparmor.profile: unconfined
lxc.cgroup.devices.allow: a
lxc.cap.drop:
lxc.cgroup2.devices.allow: c 226:0 rwm
lxc.cgroup2.devices.allow: c 226:128 rwm
lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file
lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file
</code></pre><p>这些配置参数是针对 Linux 容器（通常是 LXC 容器）的一些安全和资源控制设置，用于限制容器内部的行为和访问。以下是每个配置项的作用解释：</p><p><code>lxc.apparmor.profile: unconfined</code>：该配置指定了 AppArmor（应用程序安全性配置框架）的配置文件名称，这里设置为 &ldquo;unconfined&rdquo;，用于允许容器内的进程具有更高的系统权限</p><p><code>lxc.cgroup.devices.allow: a</code>： 允许容器内的进程访问所有的 cgroup 设备。</p><p><code>lxc.cap.drop</code>: 此配置项为空，容器内的进程将继承主机系统的默认能力设置。</p><p><code>lxc.cgroup2.devices.allow: c 226:0 rwm</code> 和 <code>lxc.cgroup2.devices.allow: c 226:128 rwm</code>： 允许容器内的进程对设备号为 <code>226:0</code> 和 <code>226:128</code> 的字符设备节点拥有读、写和映射（rwm）的权限。用于允许容器内的进程访问特定的设备，如图形加速设备。</p><p><code>lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file</code> 和
<code>lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file</code>：将主机系统上的两个设备节点 <code>/dev/dri/card0</code> 和 <code>/dev/dri/renderD128</code> 挂载到容器内的相同位置，用于允许容器内的应用程序访问图形硬件加速功能，以便执行图形相关的任务</p><p>修改完成后保存，启动 LXC 容器</p><h2 id=检查核显>检查核显</h2><p>等容器启动成功后，进入容器，使用命令行检查 <code>/dev/dri</code> 路径下挂载的文件，<code>card0</code>和 <code>renderD128</code> 都正常</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls /dev/dri/
</span></span><span style=display:flex><span>card0  renderD128
</span></span></code></pre></div><p>查看 PCI 也能看到核心显卡，说明挂载成功</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>lspci | grep VGA
</span></span><span style=display:flex><span>00:02.0 VGA compatible controller: Intel Corporation JasperLake <span style=color:#f92672>[</span>UHD Graphics<span style=color:#f92672>]</span> <span style=color:#f92672>(</span>rev 01<span style=color:#f92672>)</span>
</span></span></code></pre></div><h2 id=将显卡挂载到-docker-容器中>将显卡挂载到 Docker 容器中</h2><p>使用 docker-compose 部署 frigate，在配置文件中将设备 <code>/dev/dri/renderD128</code> 挂载到容器中即可</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>frigate</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>frigate</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>privileged</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>restart</span>: <span style=color:#ae81ff>unless-stopped</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>ghcr.io/blakeblackshear/frigate:stable</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>shm_size</span>: <span style=color:#e6db74>&#34;256mb&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>devices</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>/dev/dri/renderD128</span>
</span></span></code></pre></div><p>这样，容器就可以正常使用核显进行 ffmpeg 硬件加速了</p><h2 id=挂载-tun-设备>挂载 TUN 设备</h2><p>如果你需要在 LXC 容器中使用 WireGuard/ TailScale/Clash 等依赖 TUN 网络的设备，还需要添加以下内容：</p><pre tabindex=0><code class=language-dsconfig data-lang=dsconfig>lxc.cgroup2.devices.allow: c 10:200 rwm
lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file
</code></pre><p>否则会报错，提示找不到 Socket，这是因为 LXC 容器默认不会挂载 TUN 设备，所以无法访问</p><pre tabindex=0><code>failed to connect to local tailscaled (which appears to be running as tailscaled, pid 94512). Got error: Failed to connect to local Tailscale daemon for /localapi/v0/status; systemd tailscaled.service not running. Error: dial unix /var/run/tailscale/tailscaled.sock: connect: no such file or directory
</code></pre></section><div class=paginator><a class=prev href=https://blog.hellowood.dev/posts/%E4%BD%BF%E7%94%A8docker%E9%83%A8%E7%BD%B2clash-premium/><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M9.94496 9C9.28897 9.61644 7.63215 10.997 6.04814 11.7966 5.98257 11.8297 5.98456 11.9753 6.05061 12.0063c1.00435.4716 2.8788 1.9201 3.89435 2.9937M6.44444 11.9667C8.86549 12.0608 14 12 16 11" stroke="currentcolor" stroke-linecap="round"/></svg>
<span>使用 Docker 部署 Clash Premium</span></a>
<a class=next href=https://blog.hellowood.dev/posts/%E4%BD%BF%E7%94%A8arpl%E5%9C%A8pve%E4%B8%8A%E5%AE%89%E8%A3%85%E9%BB%91%E7%BE%A4%E6%99%96/><span>使用arpl在PVE上安装黑群晖</span><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M12.055 9C12.711 9.61644 14.3679 10.997 15.9519 11.7966 16.0174 11.8297 16.0154 11.9753 15.9494 12.0063 14.945 12.4779 13.0706 13.9264 12.055 15m3.5006-3.0333C13.1345 12.0608 8 12 6 11" stroke="currentcolor" stroke-linecap="round"/></svg></a></div></article></div><footer class=footer><p>&copy; 2024 <a href=https://blog.hellowood.dev/>HelloWood</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank data-umami-event=to-hugo>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank data-umami-event=to-ladder>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g data-umami-event=top-link><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M10.5376 22.7916C11.0152 22.7207 22.5795 21.1781 22.0978 10.4211 22.0536 9.43274 21.9303 8.53367 21.7387 7.71865M10.5376 22.7916C16.876 22.3728 20.0969 19.8899 21.5383 16.9142M10.5376 22.7916C9.7707 22.9055 8.97982 22.8964 8.19743 22.7725M21.7387 7.71865C21.4988 6.69828 21.1518 5.80967 20.7188 5.04257m1.0199 2.67608C22.6022 10.1105 23.0542 13.7848 21.5383 16.9142M20.7188 5.04257c-3.5504-6.28886-12.88753-4.410077-16.44303.0C2.88063 6.77451-.0433281 11.1668 1.38159 16.6571c.89322 3.4417 3.7911 5.6365 6.81584 6.1154M20.7188 5.04257c1.3509 1.89783 3.3111 6.34223 1.6353 10.37273M21.5383 16.9142C21.8737 16.4251 22.1428 15.9235 22.3541 15.4153M8.19743 22.7725C12.1971 23.4683 20.6281 22.971 22.3541 15.4153M14 10.945C13.3836 10.289 12.003 8.63215 11.2034 7.04814 11.1703 6.98257 11.0247 6.98456 10.9937 7.05061 10.5221 8.05496 9.07362 9.92941 8 10.945m3.0333-3.50056C10.9392 9.86549 11 15 12 17" stroke="currentcolor" stroke-linecap="round"/></svg>
</a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>