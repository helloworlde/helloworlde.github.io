<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>基于 Frigate 使用 Double Take 和 DeepStack 对视频监控进行人脸识别</title>
<meta charset=utf-8><meta name=description content='Ladder@Double Take 是一个训练和识别人脸的工具，支持对 Frigate 中检测到的人物对象进行人脸识别，可以用于统计监控中出现的人物信息。不过经过测试，只适用于门禁、闸机等有清晰人脸的场景，日常的监控因安装位置、角度等原因无法提供清晰的人脸，因此识别的准确度和有效性并不高
Double Take 的原理是通过监听 Frigate 识别到对象后发出的 MQTT 消息，根据消息获取对应事件的快照，并将其发送给识别的服务，如 Deepstack/CodeProject.AI 等，然后根据识别结果显示该事件中出现的人脸信息
Double Take 作者似乎已经放弃维护了，上次更新还是在两年前(2022-10-28)，尽管作者在今年的一月份(2024-1-7)声明计划开发 2.0 版本，但是截止到8月份也没有任何进展，看起来作者在21年成为 24G.com 这家公司的 DevOps 总监后便没有精力投入到开源项目中了；不过，另外一位作者 skrashevich 在其 fork 的仓库 skrashevich/double-take中提交了不少 2.0 版本的计划的功能
部署依赖服务 Double Take 依赖 Frigate、MQTT 和人脸识别服务，部署在使用 Intel CPU 的 NUC 上，系统是 Ubuntu 22，地址是 192.168.31.254
部署 MQTT MQTT 使用 emqx 提供的镜像进行部署，方便本地使用，参考通过 Docker 运行 EMQX
docker-compose.yaml services: mqtt: image: emqx/emqx container_name: mqtt restart: unless-stopped ports: - "1883:1883" - "8083:8083" - "8084:8084" - "8883:8883" - "18083:18083" 启动后访问 18083端口，http://192.'><meta name=author content="HelloWood"><link rel=canonical href=https://blog.hellowood.dev/posts/%E5%9F%BA%E4%BA%8E-frigate-%E4%BD%BF%E7%94%A8-double-take-%E5%92%8C-deepstack-%E5%AF%B9%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7%E8%BF%9B%E8%A1%8C%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/><meta name=google-site-verification content="G-3MSGPYTHPZ"><link rel=alternate type=application/rss+xml href=https://blog.hellowood.dev//index.xml title=HelloWood><script async src="https://www.googletagmanager.com/gtag/js?id=G-3MSGPYTHPZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-3MSGPYTHPZ")}</script><script async defer data-website-id=7a9034de-0ce7-4756-942a-829e6cd22301 src=https://umami.hellowood.dev/script.js></script><script defer data-cf-beacon='{"token": "b2e481d136dc428c8c96c8673e2a04cf"}' src=https://static.cloudflareinsights.com/beacon.min.js></script><meta property="og:url" content="https://blog.hellowood.dev/posts/%E5%9F%BA%E4%BA%8E-frigate-%E4%BD%BF%E7%94%A8-double-take-%E5%92%8C-deepstack-%E5%AF%B9%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7%E8%BF%9B%E8%A1%8C%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"><meta property="og:site_name" content="HelloWood"><meta property="og:title" content="基于 Frigate 使用 Double Take 和 DeepStack 对视频监控进行人脸识别"><meta property="og:description" content='Double Take 是一个训练和识别人脸的工具，支持对 Frigate 中检测到的人物对象进行人脸识别，可以用于统计监控中出现的人物信息。不过经过测试，只适用于门禁、闸机等有清晰人脸的场景，日常的监控因安装位置、角度等原因无法提供清晰的人脸，因此识别的准确度和有效性并不高
Double Take 的原理是通过监听 Frigate 识别到对象后发出的 MQTT 消息，根据消息获取对应事件的快照，并将其发送给识别的服务，如 Deepstack/CodeProject.AI 等，然后根据识别结果显示该事件中出现的人脸信息
Double Take 作者似乎已经放弃维护了，上次更新还是在两年前(2022-10-28)，尽管作者在今年的一月份(2024-1-7)声明计划开发 2.0 版本，但是截止到8月份也没有任何进展，看起来作者在21年成为 24G.com 这家公司的 DevOps 总监后便没有精力投入到开源项目中了；不过，另外一位作者 skrashevich 在其 fork 的仓库 skrashevich/double-take中提交了不少 2.0 版本的计划的功能
部署依赖服务 Double Take 依赖 Frigate、MQTT 和人脸识别服务，部署在使用 Intel CPU 的 NUC 上，系统是 Ubuntu 22，地址是 192.168.31.254
部署 MQTT MQTT 使用 emqx 提供的镜像进行部署，方便本地使用，参考通过 Docker 运行 EMQX
docker-compose.yaml services: mqtt: image: emqx/emqx container_name: mqtt restart: unless-stopped ports: - "1883:1883" - "8083:8083" - "8084:8084" - "8883:8883" - "18083:18083" 启动后访问 18083端口，http://192.'><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-16T09:29:49+08:00"><meta property="article:modified_time" content="2024-08-16T09:29:49+08:00"><meta property="article:tag" content="NVR"><meta property="article:tag" content="HomeLab"><meta property="article:tag" content="Frigate"><meta property="og:see_also" content="https://blog.hellowood.dev/posts/%E4%BD%BF%E7%94%A8%E5%AE%B6%E5%BA%AD%E5%AE%BD%E5%B8%A6%E5%85%AC%E7%BD%91-ipv6-%E8%87%AA%E5%BB%BA-tailscale-%E7%9A%84-derp-%E8%8A%82%E7%82%B9/"><meta property="og:see_also" content="https://blog.hellowood.dev/posts/ubuntu-22-%E7%8E%AF%E5%A2%83%E5%88%9D%E5%A7%8B%E5%8C%96/"><meta property="og:see_also" content="https://blog.hellowood.dev/posts/proxmox-ve-%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84-lxc-%E5%AE%B9%E5%99%A8-ct-%E6%A8%A1%E6%9D%BF/"><meta property="og:see_also" content="https://blog.hellowood.dev/posts/%E5%9C%A8%E9%BB%91%E7%BE%A4%E6%99%96%E4%BD%BF%E7%94%A8-docker-%E9%83%A8%E7%BD%B2-proxmox-backup-server/"><meta property="og:see_also" content="https://blog.hellowood.dev/posts/%E4%BD%BF%E7%94%A8%E9%98%BF%E5%B0%94%E5%8D%A1%E7%89%B9%E7%8C%AB%E6%A3%92%E6%9B%BF%E6%8D%A2%E5%8C%97%E4%BA%AC%E7%A7%BB%E5%8A%A8-gpon-%E5%85%89%E7%8C%AB/"><meta property="og:see_also" content="https://blog.hellowood.dev/posts/%E4%BD%BF%E7%94%A8cloudflare-tunnels%E9%80%9A%E8%BF%87web-ssh%E8%AE%BF%E9%97%AE%E6%9C%8D%E5%8A%A1%E5%99%A8/"><meta name=twitter:card content="summary"><meta name=twitter:title content="基于 Frigate 使用 Double Take 和 DeepStack 对视频监控进行人脸识别"><meta name=twitter:description content='Double Take 是一个训练和识别人脸的工具，支持对 Frigate 中检测到的人物对象进行人脸识别，可以用于统计监控中出现的人物信息。不过经过测试，只适用于门禁、闸机等有清晰人脸的场景，日常的监控因安装位置、角度等原因无法提供清晰的人脸，因此识别的准确度和有效性并不高
Double Take 的原理是通过监听 Frigate 识别到对象后发出的 MQTT 消息，根据消息获取对应事件的快照，并将其发送给识别的服务，如 Deepstack/CodeProject.AI 等，然后根据识别结果显示该事件中出现的人脸信息
Double Take 作者似乎已经放弃维护了，上次更新还是在两年前(2022-10-28)，尽管作者在今年的一月份(2024-1-7)声明计划开发 2.0 版本，但是截止到8月份也没有任何进展，看起来作者在21年成为 24G.com 这家公司的 DevOps 总监后便没有精力投入到开源项目中了；不过，另外一位作者 skrashevich 在其 fork 的仓库 skrashevich/double-take中提交了不少 2.0 版本的计划的功能
部署依赖服务 Double Take 依赖 Frigate、MQTT 和人脸识别服务，部署在使用 Intel CPU 的 NUC 上，系统是 Ubuntu 22，地址是 192.168.31.254
部署 MQTT MQTT 使用 emqx 提供的镜像进行部署，方便本地使用，参考通过 Docker 运行 EMQX
docker-compose.yaml services: mqtt: image: emqx/emqx container_name: mqtt restart: unless-stopped ports: - "1883:1883" - "8083:8083" - "8084:8084" - "8883:8883" - "18083:18083" 启动后访问 18083端口，http://192.'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.hellowood.dev/posts/"},{"@type":"ListItem","position":2,"name":"基于 Frigate 使用 Double Take 和 DeepStack 对视频监控进行人脸识别","item":"https://blog.hellowood.dev/posts/%E5%9F%BA%E4%BA%8E-frigate-%E4%BD%BF%E7%94%A8-double-take-%E5%92%8C-deepstack-%E5%AF%B9%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7%E8%BF%9B%E8%A1%8C%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"基于 Frigate 使用 Double Take 和 DeepStack 对视频监控进行人脸识别","name":"基于 Frigate 使用 Double Take 和 DeepStack 对视频监控进行人脸识别","description":"Double Take 是一个训练和识别人脸的工具，支持对 Frigate 中检测到的人物对象进行人脸识别，可以用于统计监控中出现的人物信息。不过经过测试，只适用于门禁、闸机等有清晰人脸的场景，日常的监控因安装位置、角度等原因无法提供清晰的人脸，因此识别的准确度和有效性并不高\nDouble Take 的原理是通过监听 Frigate 识别到对象后发出的 MQTT 消息，根据消息获取对应事件的快照，并将其发送给识别的服务，如 Deepstack/CodeProject.AI 等，然后根据识别结果显示该事件中出现的人脸信息\nDouble Take 作者似乎已经放弃维护了，上次更新还是在两年前(2022-10-28)，尽管作者在今年的一月份(2024-1-7)声明计划开发 2.0 版本，但是截止到8月份也没有任何进展，看起来作者在21年成为 24G.com 这家公司的 DevOps 总监后便没有精力投入到开源项目中了；不过，另外一位作者 skrashevich 在其 fork 的仓库 skrashevich/double-take中提交了不少 2.0 版本的计划的功能\n部署依赖服务 Double Take 依赖 Frigate、MQTT 和人脸识别服务，部署在使用 Intel CPU 的 NUC 上，系统是 Ubuntu 22，地址是 192.168.31.254\n部署 MQTT MQTT 使用 emqx 提供的镜像进行部署，方便本地使用，参考通过 Docker 运行 EMQX\ndocker-compose.yaml services: mqtt: image: emqx/emqx container_name: mqtt restart: unless-stopped ports: - \u0026#34;1883:1883\u0026#34; - \u0026#34;8083:8083\u0026#34; - \u0026#34;8084:8084\u0026#34; - \u0026#34;8883:8883\u0026#34; - \u0026#34;18083:18083\u0026#34; 启动后访问 18083端口，http://192.","keywords":["NVR","HomeLab","Frigate"],"articleBody":"Double Take 是一个训练和识别人脸的工具，支持对 Frigate 中检测到的人物对象进行人脸识别，可以用于统计监控中出现的人物信息。不过经过测试，只适用于门禁、闸机等有清晰人脸的场景，日常的监控因安装位置、角度等原因无法提供清晰的人脸，因此识别的准确度和有效性并不高\nDouble Take 的原理是通过监听 Frigate 识别到对象后发出的 MQTT 消息，根据消息获取对应事件的快照，并将其发送给识别的服务，如 Deepstack/CodeProject.AI 等，然后根据识别结果显示该事件中出现的人脸信息\nDouble Take 作者似乎已经放弃维护了，上次更新还是在两年前(2022-10-28)，尽管作者在今年的一月份(2024-1-7)声明计划开发 2.0 版本，但是截止到8月份也没有任何进展，看起来作者在21年成为 24G.com 这家公司的 DevOps 总监后便没有精力投入到开源项目中了；不过，另外一位作者 skrashevich 在其 fork 的仓库 skrashevich/double-take中提交了不少 2.0 版本的计划的功能\n部署依赖服务 Double Take 依赖 Frigate、MQTT 和人脸识别服务，部署在使用 Intel CPU 的 NUC 上，系统是 Ubuntu 22，地址是 192.168.31.254\n部署 MQTT MQTT 使用 emqx 提供的镜像进行部署，方便本地使用，参考通过 Docker 运行 EMQX\ndocker-compose.yaml services: mqtt: image: emqx/emqx container_name: mqtt restart: unless-stopped ports: - \"1883:1883\" - \"8083:8083\" - \"8084:8084\" - \"8883:8883\" - \"18083:18083\" 启动后访问 18083端口，http://192.168.31.254:18083/，默认的用户名密码是 admin，密码是 public\n部署 Frigate 为了快速使用，Frigate 使用 Intel GPU 进行识别，如果监控不多，大多数的 NUC 和台式机都是可以满足识别诉求\ndocker-compose.yaml 将显卡挂载到容器中，用于对象识别；同时将数据目录映射到宿主机，保存相关的数据，避免容器销毁后数据丢失\nservices: frigate: container_name: frigate privileged: true restart: unless-stopped image: ghcr.io/blakeblackshear/frigate:stable shm_size: 512mb devices: - /dev/dri/renderD128 volumes: - /etc/localtime:/etc/localtime:ro - ./config/:/config - ./data/db/:/data/db - ./data/storage:/media/frigate - type: tmpfs target: /tmp/cache tmpfs: size: 1000000000 ports: - 5000:5000 environment: - TZ=Asia/Shanghai config/config.yml Frigate 的配置文件，详细参考 Full Reference Config\nmqtt: enabled: True host: 192.168.31.254 port: 1883 database: path: /data/db/frigate.db # 监听 RTSP 地址 cameras: door: ffmpeg: inputs: - path: rtsp://admin:12345678@192.168.2.252:554/stream1\u0026channel=1 roles: - record - detect # 使用 GPU 进行检测 detectors: ov: type: openvino device: GPU # OpenVINO 需要指定模型信息 model: width: 300 height: 300 input_tensor: nhwc input_pixel_format: bgr path: /openvino-model/ssdlite_mobilenet_v2.xml labelmap_path: /openvino-model/coco_91cl_bkgr.txt # 使用 GPU 加速 ffmpeg ffmpeg: hwaccel_args: preset-vaapi # 检测对象 objects: track: - person # 保留快照 snapshots: enabled: True bounding_box: False 启动后，访问 http://192.168.31.254:5000 进入 Frigate 人脸识别服务 Double Take 支持多种探测器，分别是：CompreFace、Amazon Rekognition、DeepStack、CodeProject.AI Server 和 Facebox(Machine Box)，其中 Amazon Rekognition 和 Facebox(Machine Box) 需要上传或者上传部分数据，不符合隐私保护的诉求；其他项目对比如下\n对比项目 CompreFace DeepStack CodeProject.AI Server 图形化界面 有 无 有 支持模型 人脸相关模型 人脸检测、对象识别、对象分类 人脸检测、对象识别、对象分类、自定义模型 自定义模型 不支持 支持自定义模型 支持自定义模型 最后更新时间 2023-11-14 2022-07-01 2024-05-22 是否支持 GPU 支持 支持 支持 加速器支持 不支持 Jetson Google Coral TPU 人脸检测 检测不准确，需有明确人脸 检测准确，正脸/侧脸均可识别 检测准确，正脸/侧脸均可识别 人脸识别 准确度高 小面积人脸识别不准确 小面积人脸识别不准确 DeepStack 使用最简单，因此使用 DeepStack 进行测试\ndocker-compose.yaml services: deepstack: image: deepquestai/deepstack container_name: deepstack restart: unless-stopped environment: - VISION-FACE=True volumes: - ./data:/datastore ports: - \"5002:5000\" Double Take 部署 Double Take docker-compose.yaml services: double-take: container_name: double-take image: skrashevich/double-take restart: unless-stopped volumes: - ./data:/.storage ports: - 3000:3000 配置 Double Take 启动 Double Take，添加配置\nmqtt: host: 192.168.2.254 topics: frigate: frigate/events matches: double-take/matches cameras: double-take/cameras detect: match: save: true # 最低置信度 confidence: 60 # 保留时间，单位是小时 purge: 168 unknown: save: true # 保留未识别的 frigate: url: http://192.168.2.254:5000 # 识别对象 labels: - person # 使用 deepstack 识别 detectors: deepstack: url: http://192.168.2.254:5002 timeout: 15 保存配置后重新启动 Double Take，当监控中出现人脸时会自动进行检测；可以选择部分进行训练，或者上传已经准备好的照片进行训练，当下次出现时即可进行识别\n参考文档 Third Party Extensions double-take CompreFace DeepStack CodeProject.AI Facebox Amazon Rekognition ","wordCount":"371","inLanguage":"en","datePublished":"2024-08-16T09:29:49+08:00","dateModified":"2024-08-16T09:29:49+08:00","author":{"@type":"Person","name":"HelloWood"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.hellowood.dev/posts/%E5%9F%BA%E4%BA%8E-frigate-%E4%BD%BF%E7%94%A8-double-take-%E5%92%8C-deepstack-%E5%AF%B9%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7%E8%BF%9B%E8%A1%8C%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"},"publisher":{"@type":"Organization","name":"HelloWood","logo":{"@type":"ImageObject","url":"https://blog.hellowood.dev/favicon.ico"}}}</script><link rel=icon href=/images/avatar.png sizes=16x16><link rel=apple-touch-icon href=/images/avatar.png><link rel=manifest href=/images/avatar.png><link rel=stylesheet href=https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css><link rel=stylesheet href=/css/main.min.7f82854fa0e999ec07c4835d3029de9f484030e254b80d470b3ca48eb934720e.css integrity="sha256-f4KFT6DpmewHxINdMCnen0hAMOJUuA1HCzykjrk0cg4=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.c607d6febd16934a82eb61d3a896ed9d869f54373cc63ce95864ed5488fe3128.js></script><script>hljs.highlightAll()</script><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><meta name=google-adsense-account content="ca-pub-3401351766168985"><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","jtbhx98g62")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3401351766168985" crossorigin=anonymous></script><script defer src=https://analytics.us.umami.is/script.js data-website-id=73ff1c8c-9938-43cf-81af-e77e26b0cca3></script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand data-umami-event=navigation-brand href=/>HOME
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Blog href=/posts>Blog</a></li><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Tags href=/tags>Tags</a></li><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Archive href=/archives>Archive</a></li><li class="navigation-item navigation-menu"><a class=navigation-link data-umami-event=Dashboard href=https://umami.hellowood.dev/share/lab/Blog>Dashboard</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link data-umami-event=navigation-social href=https://github.com/helloworlde><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button data-umami-event=toggle-theme aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span>
<span class=toggle-light><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>基于 Frigate 使用 Double Take 和 DeepStack 对视频监控进行人脸识别</h1></header><p><small>August 16, 2024&nbsp;· 371 words&nbsp;· 2 min</small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#部署依赖服务>部署依赖服务</a><ul><li><a href=#部署-mqtt>部署 MQTT</a></li><li><a href=#部署-frigate>部署 Frigate</a></li></ul></li><li><a href=#人脸识别服务>人脸识别服务</a></li><li><a href=#double-take>Double Take</a><ul><li><a href=#部署-double-take>部署 Double Take</a></li><li><a href=#配置-double-take>配置 Double Take</a></li></ul></li><li><a href=#参考文档>参考文档</a></li></ul></nav></div><section class=blog-content><p>Double Take 是一个训练和识别人脸的工具，支持对 Frigate 中检测到的人物对象进行人脸识别，可以用于统计监控中出现的人物信息。不过经过测试，只适用于门禁、闸机等有清晰人脸的场景，日常的监控因安装位置、角度等原因无法提供清晰的人脸，因此识别的准确度和有效性并不高</p><p><img alt=homelab-frigate-double-take-face-double-take-detect.png src=https://img.hellowood.dev/picture/homelab-frigate-double-take-face-double-take-detect.png></p><p>Double Take 的原理是通过监听 Frigate 识别到对象后发出的 MQTT 消息，根据消息获取对应事件的快照，并将其发送给识别的服务，如 Deepstack/CodeProject.AI 等，然后根据识别结果显示该事件中出现的人脸信息</p><p>Double Take 作者似乎已经放弃维护了，上次更新还是在两年前(2022-10-28)，尽管作者在今年的一月份(2024-1-7)声明计划<a href=https://github.com/jakowenko/double-take/issues/343>开发 2.0 版本</a>，但是截止到8月份也没有任何进展，看起来作者在21年成为 24G.com 这家公司的 DevOps 总监后便没有精力投入到开源项目中了；不过，另外一位作者 skrashevich 在其 fork 的仓库 <a href=https://github.com/skrashevich/double-take>skrashevich/double-take</a>中提交了不少 2.0 版本的计划的功能</p><h2 id=部署依赖服务>部署依赖服务</h2><p>Double Take 依赖 Frigate、MQTT 和人脸识别服务，部署在使用 Intel CPU 的 NUC 上，系统是 Ubuntu 22，地址是 192.168.31.254</p><h3 id=部署-mqtt>部署 MQTT</h3><p>MQTT 使用 emqx 提供的镜像进行部署，方便本地使用，参考<a href=https://docs.emqx.com/zh/emqx/latest/deploy/install-docker-ce.html>通过 Docker 运行 EMQX</a></p><ul><li>docker-compose.yaml</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>mqtt</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>emqx/emqx</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>mqtt</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>restart</span>: <span style=color:#ae81ff>unless-stopped</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;1883:1883&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8083:8083&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8084:8084&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8883:8883&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;18083:18083&#34;</span>
</span></span></code></pre></div><p>启动后访问 18083端口，<a href=http://192.168.31.254:18083/>http://192.168.31.254:18083/</a>，默认的用户名密码是 <code>admin</code>，密码是 <code>public</code></p><p><img alt=homelab-frigate-double-take-face-mqtt.png src=https://img.hellowood.dev/picture/homelab-frigate-double-take-face-mqtt.png></p><h3 id=部署-frigate>部署 Frigate</h3><p>为了快速使用，Frigate 使用 Intel GPU 进行识别，如果监控不多，大多数的 NUC 和台式机都是可以满足识别诉求</p><ul><li><code>docker-compose.yaml</code></li></ul><p>将显卡挂载到容器中，用于对象识别；同时将数据目录映射到宿主机，保存相关的数据，避免容器销毁后数据丢失</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>frigate</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>frigate</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>privileged</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>restart</span>: <span style=color:#ae81ff>unless-stopped</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>ghcr.io/blakeblackshear/frigate:stable</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>shm_size</span>: <span style=color:#ae81ff>512mb</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>devices</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>/dev/dri/renderD128</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>/etc/localtime:/etc/localtime:ro</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>./config/:/config</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>./data/db/:/data/db</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>./data/storage:/media/frigate</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>type</span>: <span style=color:#ae81ff>tmpfs</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>target</span>: <span style=color:#ae81ff>/tmp/cache</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>tmpfs</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>size</span>: <span style=color:#ae81ff>1000000000</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>5000</span>:<span style=color:#ae81ff>5000</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>environment</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>TZ=Asia/Shanghai</span>
</span></span></code></pre></div><ul><li><code>config/config.yml</code></li></ul><p>Frigate 的配置文件，详细参考 <a href=https://docs.frigate.video/configuration/reference/>Full Reference Config</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>mqtt</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>host</span>: <span style=color:#ae81ff>192.168.31.254</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>port</span>: <span style=color:#ae81ff>1883</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>database</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/data/db/frigate.db</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 监听 RTSP 地址</span>
</span></span><span style=display:flex><span><span style=color:#f92672>cameras</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>door</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>ffmpeg</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>inputs</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>path</span>: <span style=color:#ae81ff>rtsp://admin:12345678@192.168.2.252:554/stream1&amp;channel=1</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>roles</span>:
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>record</span>
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>detect</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用 GPU 进行检测</span>
</span></span><span style=display:flex><span><span style=color:#f92672>detectors</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>ov</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>openvino</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>device</span>: <span style=color:#ae81ff>GPU</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># OpenVINO 需要指定模型信息</span>
</span></span><span style=display:flex><span><span style=color:#f92672>model</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>width</span>: <span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>height</span>: <span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>input_tensor</span>: <span style=color:#ae81ff>nhwc</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>input_pixel_format</span>: <span style=color:#ae81ff>bgr</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/openvino-model/ssdlite_mobilenet_v2.xml</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>labelmap_path</span>: <span style=color:#ae81ff>/openvino-model/coco_91cl_bkgr.txt</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用 GPU 加速 ffmpeg</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ffmpeg</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>hwaccel_args</span>: <span style=color:#ae81ff>preset-vaapi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检测对象</span>
</span></span><span style=display:flex><span><span style=color:#f92672>objects</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>track</span>:
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>person</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 保留快照</span>
</span></span><span style=display:flex><span><span style=color:#f92672>snapshots</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>bounding_box</span>: <span style=color:#66d9ef>False</span>
</span></span></code></pre></div><p>启动后，访问 <a href=http://192.168.31.254:5000>http://192.168.31.254:5000</a> 进入 Frigate
<img alt=homelab-frigate-double-take-face-frigate.png src=https://img.hellowood.dev/picture/homelab-frigate-double-take-face-frigate.png></p><h2 id=人脸识别服务>人脸识别服务</h2><p>Double Take 支持多种探测器，分别是：CompreFace、Amazon Rekognition、DeepStack、CodeProject.AI Server 和 Facebox(Machine Box)，其中 Amazon Rekognition 和 Facebox(Machine Box) 需要上传或者上传部分数据，不符合隐私保护的诉求；其他项目对比如下</p><table><thead><tr><th style=text-align:left>对比项目</th><th style=text-align:left>CompreFace</th><th style=text-align:left>DeepStack</th><th style=text-align:left>CodeProject.AI Server</th></tr></thead><tbody><tr><td style=text-align:left>图形化界面</td><td style=text-align:left>有</td><td style=text-align:left>无</td><td style=text-align:left>有</td></tr><tr><td style=text-align:left>支持模型</td><td style=text-align:left>人脸相关模型</td><td style=text-align:left>人脸检测、对象识别、对象分类</td><td style=text-align:left>人脸检测、对象识别、对象分类、自定义模型</td></tr><tr><td style=text-align:left>自定义模型</td><td style=text-align:left>不支持</td><td style=text-align:left>支持自定义模型</td><td style=text-align:left>支持自定义模型</td></tr><tr><td style=text-align:left>最后更新时间</td><td style=text-align:left>2023-11-14</td><td style=text-align:left>2022-07-01</td><td style=text-align:left>2024-05-22</td></tr><tr><td style=text-align:left>是否支持 GPU</td><td style=text-align:left>支持</td><td style=text-align:left>支持</td><td style=text-align:left>支持</td></tr><tr><td style=text-align:left>加速器支持</td><td style=text-align:left>不支持</td><td style=text-align:left>Jetson</td><td style=text-align:left>Google Coral TPU</td></tr><tr><td style=text-align:left>人脸检测</td><td style=text-align:left>检测不准确，需有明确人脸</td><td style=text-align:left>检测准确，正脸/侧脸均可识别</td><td style=text-align:left>检测准确，正脸/侧脸均可识别</td></tr><tr><td style=text-align:left>人脸识别</td><td style=text-align:left>准确度高</td><td style=text-align:left>小面积人脸识别不准确</td><td style=text-align:left>小面积人脸识别不准确</td></tr></tbody></table><p>DeepStack 使用最简单，因此使用 DeepStack 进行测试</p><ul><li>docker-compose.yaml</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>deepstack</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>deepquestai/deepstack</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>deepstack</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>restart</span>: <span style=color:#ae81ff>unless-stopped</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>environment</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>VISION-FACE=True</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>./data:/datastore</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;5002:5000&#34;</span>
</span></span></code></pre></div><h2 id=double-take>Double Take</h2><h3 id=部署-double-take>部署 Double Take</h3><ul><li>docker-compose.yaml</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>double-take</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>double-take</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>skrashevich/double-take</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>restart</span>: <span style=color:#ae81ff>unless-stopped</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>./data:/.storage</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>3000</span>:<span style=color:#ae81ff>3000</span>
</span></span></code></pre></div><h3 id=配置-double-take>配置 Double Take</h3><p>启动 Double Take，添加配置</p><p><img alt=homelab-frigate-double-take-face-double-take-config.png src=https://img.hellowood.dev/picture/homelab-frigate-double-take-face-double-take-config.png></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>mqtt</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>host</span>: <span style=color:#ae81ff>192.168.2.254</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>topics</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>frigate</span>: <span style=color:#ae81ff>frigate/events</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>matches</span>: <span style=color:#ae81ff>double-take/matches</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>cameras</span>: <span style=color:#ae81ff>double-take/cameras</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#f92672>detect</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>match</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>save</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 最低置信度</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>confidence</span>: <span style=color:#ae81ff>60</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 保留时间，单位是小时</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>purge</span>: <span style=color:#ae81ff>168</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>unknown</span>: 
</span></span><span style=display:flex><span>    <span style=color:#f92672>save</span>: <span style=color:#66d9ef>true</span> <span style=color:#75715e># 保留未识别的</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>frigate</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>url</span>: <span style=color:#ae81ff>http://192.168.2.254:5000</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># 识别对象</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>person</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用 deepstack 识别</span>
</span></span><span style=display:flex><span><span style=color:#f92672>detectors</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>deepstack</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>url</span>: <span style=color:#ae81ff>http://192.168.2.254:5002</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>timeout</span>: <span style=color:#ae81ff>15</span>
</span></span></code></pre></div><p>保存配置后重新启动 Double Take，当监控中出现人脸时会自动进行检测；可以选择部分进行训练，或者上传已经准备好的照片进行训练，当下次出现时即可进行识别</p><p><img alt=homelab-frigate-double-take-face-double-take-detect.png src=https://img.hellowood.dev/picture/homelab-frigate-double-take-face-double-take-detect.png></p><h2 id=参考文档>参考文档</h2><ul><li><a href=https://docs.frigate.video/integrations/third_party_extensions>Third Party Extensions</a></li><li><a href=https://github.com/skrashevich/double-take>double-take</a></li><li><a href=https://github.com/exadel-inc/CompreFace>CompreFace</a></li><li><a href=https://github.com/johnolafenwa/DeepStack>DeepStack</a></li><li><a href=https://www.codeproject.com/AI/docs/index.html>CodeProject.AI</a></li><li><a href=https://machinebox.io/>Facebox</a></li><li><a href=https://aws.amazon.com/cn/rekognition/>Amazon Rekognition</a></li></ul></section><div class=paginator><a class=prev href=https://blog.hellowood.dev/posts/ubuntu22-%E5%AE%89%E8%A3%85%E5%88%9D%E5%A7%8B%E5%8C%96-hailo-8%E7%B3%BB%E5%88%97-tpu-%E5%8A%A0%E9%80%9F%E5%99%A8/><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M9.94496 9C9.28897 9.61644 7.63215 10.997 6.04814 11.7966 5.98257 11.8297 5.98456 11.9753 6.05061 12.0063c1.00435.4716 2.8788 1.9201 3.89435 2.9937M6.44444 11.9667C8.86549 12.0608 14 12 16 11" stroke="currentcolor" stroke-linecap="round"/></svg>
<span>Ubuntu22 安装初始化 Hailo 8系列 TPU 加速器</span></a>
<a class=next href=https://blog.hellowood.dev/posts/ubuntu-22-%E5%9C%A8-docker-%E5%AE%B9%E5%99%A8%E4%B8%AD%E4%BD%BF%E7%94%A8-nvidia-%E6%98%BE%E5%8D%A1/><span>Ubuntu 22 在 Docker 容器中使用 NVIDIA 显卡</span><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M12.055 9C12.711 9.61644 14.3679 10.997 15.9519 11.7966 16.0174 11.8297 16.0154 11.9753 15.9494 12.0063 14.945 12.4779 13.0706 13.9264 12.055 15m3.5006-3.0333C13.1345 12.0608 8 12 6 11" stroke="currentcolor" stroke-linecap="round"/></svg></a></div><div class=related-resources><h3>Related Resources</h3><nav><ul><li><a href=/posts/%E4%BD%BF%E7%94%A8%E5%AE%B6%E5%BA%AD%E5%AE%BD%E5%B8%A6%E5%85%AC%E7%BD%91-ipv6-%E8%87%AA%E5%BB%BA-tailscale-%E7%9A%84-derp-%E8%8A%82%E7%82%B9/>使用家庭宽带公网 IPV6 自建 Tailscale 的 DERP 节点</a></li><li><a href=/posts/ubuntu-22-%E7%8E%AF%E5%A2%83%E5%88%9D%E5%A7%8B%E5%8C%96/>Ubuntu 22 环境初始化</a></li><li><a href=/posts/proxmox-ve-%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84-lxc-%E5%AE%B9%E5%99%A8-ct-%E6%A8%A1%E6%9D%BF/>Proxmox VE 创建自定义的 LXC 容器 CT 模板</a></li><li><a href=/posts/%E5%9C%A8%E9%BB%91%E7%BE%A4%E6%99%96%E4%BD%BF%E7%94%A8-docker-%E9%83%A8%E7%BD%B2-proxmox-backup-server/>在黑群晖使用 Docker 部署 Proxmox Backup Server</a></li><li><a href=/posts/%E4%BD%BF%E7%94%A8%E9%98%BF%E5%B0%94%E5%8D%A1%E7%89%B9%E7%8C%AB%E6%A3%92%E6%9B%BF%E6%8D%A2%E5%8C%97%E4%BA%AC%E7%A7%BB%E5%8A%A8-gpon-%E5%85%89%E7%8C%AB/>使用阿尔卡特猫棒替换北京移动 GPON 光猫</a></li><li><a href=/posts/%E4%BD%BF%E7%94%A8cloudflare-tunnels%E9%80%9A%E8%BF%87web-ssh%E8%AE%BF%E9%97%AE%E6%9C%8D%E5%8A%A1%E5%99%A8/>使用 Cloudflare Tunnels 通过 Web SSH 访问服务器</a></li><li><a href=/posts/linux%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8D%E9%97%B4%E6%96%AD%E7%94%B5%E6%BA%90ups/>Linux 环境下配置不间断电源 UPS</a></li><li><a href=/posts/%E4%BD%BF%E7%94%A8-ubuntu-%E6%90%AD%E5%BB%BA-nfs-%E6%9C%8D%E5%8A%A1%E5%99%A8/>使用 Ubuntu 搭建 NFS 服务器</a></li></ul></nav></div></article></div><footer class=footer><p>&copy; 2024 <a href=https://blog.hellowood.dev/>HelloWood</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank data-umami-event=to-hugo>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank data-umami-event=to-ladder>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g data-umami-event=top-link><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M10.5376 22.7916C11.0152 22.7207 22.5795 21.1781 22.0978 10.4211 22.0536 9.43274 21.9303 8.53367 21.7387 7.71865M10.5376 22.7916C16.876 22.3728 20.0969 19.8899 21.5383 16.9142M10.5376 22.7916C9.7707 22.9055 8.97982 22.8964 8.19743 22.7725M21.7387 7.71865C21.4988 6.69828 21.1518 5.80967 20.7188 5.04257m1.0199 2.67608C22.6022 10.1105 23.0542 13.7848 21.5383 16.9142M20.7188 5.04257c-3.5504-6.28886-12.88753-4.410077-16.44303.0C2.88063 6.77451-.0433281 11.1668 1.38159 16.6571c.89322 3.4417 3.7911 5.6365 6.81584 6.1154M20.7188 5.04257c1.3509 1.89783 3.3111 6.34223 1.6353 10.37273M21.5383 16.9142C21.8737 16.4251 22.1428 15.9235 22.3541 15.4153M8.19743 22.7725C12.1971 23.4683 20.6281 22.971 22.3541 15.4153M14 10.945C13.3836 10.289 12.003 8.63215 11.2034 7.04814 11.1703 6.98257 11.0247 6.98456 10.9937 7.05061 10.5221 8.05496 9.07362 9.92941 8 10.945m3.0333-3.50056C10.9392 9.86549 11 15 12 17" stroke="currentcolor" stroke-linecap="round"/></svg>
</a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>